{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/annazan/fAIr-utilities/outputs/accuracies\n",
      "/home/annazan/fAIr-utilities/outputs/accuracies\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.environ.update(os.environ)\n",
    "# Add a new environment variable to the operating system\n",
    "os.environ[\"RAMP_HOME\"] = os.getcwd()\n",
    "# Print the environment variables to verify that the new variable was added\n",
    "print(os.environ[\"RAMP_HOME\"])\n",
    "# sys.path.append('../')\n",
    "sys.path.append('ramp-code/')\n",
    "\n",
    "# used later on in the script:\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# initialise keras\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Current working directory /home/annazan/fAIr-utilities/\n",
      "['model114_td399_bch8_epc20.csv', 'graph_model98_td373_bch16_epc20.png', 'model110_td394_bch8_epc20.csv', 'history_model112_td397_bch2_epc20.npy', 'graph_model114_td399_bch16_epc20.png', 'graph_model112_td397_bch2_epc20.png', 'graph_model97_td372_bch4_epc20.png', 'graph_model95_td370_bch2_epc20.png', 'history_model113_td398_bch16_epc20.npy', 'model112_td397_bch4_epc20.csv', 'history_model113_td398_bch2_epc20.npy', 'graph_model113_td398_bch8_epc20.png', 'model51_td364_bch2_epc20.csv', 'graph_model112_td397_bch4_epc20.png', 'model98_td373_bch4_epc20.csv', 'model114_td399_bch2_epc20.csv', 'history_model97_td372_bch2_epc20.npy', 'history_model98_td373_bch2_epc20.npy', 'history_model110_td394_bch8_epc20.npy', 'model51_td364_bch4_epc20.csv', 'history_model51_td364_bch2_epc20.npy', 'graph_model51_td364_bch8_epc20.png', 'graph_model110_td394_bch16_epc20.png', 'graph_model95_td370_bch16_epc20.png', 'model113_td398_bch4_epc20.csv', 'graph_model98_td373_bch8_epc20.png', 'history_model98_td373_bch16_epc20.npy', 'graph_model95_td370_bch4_epc20.png', 'graph_model51_td364_bch2_epc1.png', 'model114_td399_bch4_epc20.csv', 'history_model97_td372_bch8_epc5.npy', 'graph_model97_td372_bch16_epc20.png', 'history_model114_td399_bch4_epc20.npy', 'model113_td398_bch2_epc20.csv', 'graph_model98_td373_bch4_epc20.png', 'graph_model98_td373_bch2_epc20.png', 'history_model95_td370_bch8_epc20.npy', 'model110_td394_bch4_epc20.csv', 'history_model114_td399_bch2_epc20.npy', 'history_model51_td364_bch8_epc20.npy', 'graph_model97_td372_bch2_epc20.png', 'model112_td397_bch2_epc20.csv', 'model51_td364_bch2_epc1.csv', 'graph_model51_td364_bch4_epc20.png', 'history_model51_td364_bch16_epc20.npy', 'model98_td373_bch16_epc20.csv', 'model97_td372_bch8_epc20.csv', 'history_model51_td364_bch2_epc1.npy', 'history_model114_td399_bch16_epc20.npy', 'model95_td370_bch2_epc20.csv', 'graph_model110_td394_bch4_epc20.png', 'graph_model112_td397_bch16_epc20.png', 'history_model112_td397_bch8_epc20.npy', 'history_model112_td397_bch16_epc20.npy', 'graph_model51_td364_bch16_epc20.png', 'graph_model95_td370_bch8_epc20.png', 'graph_model97_td372_bch2_epc1.png', 'model95_td370_bch16_epc20.csv', 'graph_model114_td399_bch2_epc20.png', 'graph_model113_td398_bch4_epc20.png', 'graph_model112_td397_bch8_epc20.png', 'graph_model113_td398_bch2_epc20.png', 'history_model97_td372_bch2_epc1.npy', 'model110_td394_bch16_epc20.csv', 'history_model110_td394_bch16_epc20.npy', 'history_model110_td394_bch2_epc20.npy', 'graph_model97_td372_bch8_epc5.png', 'model114_td399_bch16_epc20.csv', 'model110_td394_bch2_epc20.csv', 'graph_model113_td398_bch16_epc20.png', 'history_model98_td373_bch4_epc20.npy', 'history_model98_td373_bch8_epc20.npy', 'history_model95_td370_bch16_epc20.npy', 'model113_td398_bch8_epc20.csv', 'model51_td364_bch8_epc20.csv', 'model97_td372_bch2_epc1.csv', 'model112_td397_bch16_epc20.csv', 'model97_td372_bch2_epc20.csv', 'model112_td397_bch8_epc20.csv', 'history_model113_td398_bch8_epc20.npy', 'graph_model110_td394_bch8_epc20.png', 'history_model97_td372_bch16_epc20.npy', 'model97_td372_bch8_epc5.csv', 'graph_model110_td394_bch2_epc20.png', 'model98_td373_bch2_epc20.csv', 'graph_model51_td364_bch2_epc20.png', 'history_model95_td370_bch4_epc20.npy', 'graph_model97_td372_bch8_epc20.png', 'history_model51_td364_bch4_epc20.npy', 'history_model110_td394_bch4_epc20.npy', 'history_model95_td370_bch2_epc20.npy', 'model95_td370_bch8_epc20.csv', 'model98_td373_bch8_epc20.csv', 'model51_td364_bch16_epc20.csv', 'history_model112_td397_bch4_epc20.npy', 'model113_td398_bch16_epc20.csv', 'history_model113_td398_bch4_epc20.npy', 'graph_model114_td399_bch4_epc20.png', 'graph_model114_td399_bch8_epc20.png', 'model95_td370_bch4_epc20.csv', 'history_model97_td372_bch8_epc20.npy', 'model97_td372_bch16_epc20.csv', 'history_model97_td372_bch4_epc20.npy', 'model97_td372_bch4_epc20.csv', 'history_model114_td399_bch8_epc20.npy']\n"
     ]
    }
   ],
   "source": [
    "### defining path variables\n",
    "# base_path = \"/Users/azanchetta/fAIr-utilities\" # this path is used in all the rest of the code, so change accordingly\n",
    "base_path = '/home/annazan/fAIr-utilities/'\n",
    "\n",
    "print(f\"\\n---\\nCurrent working directory {base_path}\")\n",
    "history_dir = f'{base_path}/outputs/accuracies/'\n",
    "\n",
    "dir_list = os.listdir(history_dir)\n",
    "print(dir_list)\n",
    "# from pathlib import Path\n",
    "\n",
    "# Path(dir_list).stem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "os.chdir(history_dir)\n",
    "files_list = []\n",
    "for file in glob.glob(\"*.npy\"):\n",
    "    files_list.append(file)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in files_list:\n",
    "    print(f'name is: {name}')\n",
    "    name_parts = name.split(\"_\")\n",
    "    # print(f'name is: {name_parts}')\n",
    "    city = f'{name_parts[1]}_{name_parts[2]}'\n",
    "    # print(f'city {city}')\n",
    "    name_for_graph = f'{city}_{name_parts[3]}_{name_parts[4]}'\n",
    "    name_noextension = name_for_graph.split(\".\")[0]\n",
    "    print(name_noextension)\n",
    "    \n",
    "    history_name_with_path = f'{history_dir}/{name}'\n",
    "    \n",
    "    # load the history\n",
    "    history_saved=np.load(history_name_with_path,allow_pickle='TRUE').item()\n",
    "    # history_saved.keys()\n",
    "\n",
    "    # save to dataframe\n",
    "    history_saved_df = pd.DataFrame.from_dict(history_saved)\n",
    "    # history_saved_df\n",
    "\n",
    "    # plot the training and validation accuracy and loss at each epoch\n",
    "    print(\"Generating graphs ....\")\n",
    "    # graph_file_name = f'graph_{city}_bch{n_of_batches}_epc{n_of_epochs}.png'\n",
    "    graph_file_name = f'graph_{name_noextension}.png'\n",
    "    graph_output = f'{history_dir}/{graph_file_name}'\n",
    "\n",
    "    loss = history_df[:,\"loss\"]\n",
    "    # val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "    # val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "    #---\n",
    "    acc =  history_df[:,\"categorical_accuracy\"]\n",
    "    val_acc =  history_df[:,\"val_categorical_accuracy\"]\n",
    "    acc1 =  history_df[:,\"recall_1\"]\n",
    "    val_acc1 = history.history[\"val_recall_1\"]\n",
    "    acc2 =  history_df[:,\"precision_1\"]\n",
    "    val_acc2 = history.history[\"val_precision_1\"]\n",
    "    acc3 = history.history[\"ohe_iou\"]\n",
    "    val_acc3 = history.history[\"val_ohe_iou\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    #---\n",
    "\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.plot(epochs, acc, \"y\", label=\"Train cat accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"y\", linestyle='dashed', label=\"Valid cat accuracy\")\n",
    "    plt.plot(epochs, acc1, \"b\", label=\"Train recall\")\n",
    "    plt.plot(epochs, val_acc1, \"b\", linestyle='dashed', label=\"Valid recall\")\n",
    "    plt.plot(epochs, acc2, \"c\", label=\"Train precision\")\n",
    "    plt.plot(epochs, val_acc2, \"c\", linestyle='dashed', label=\"Valid precision\")\n",
    "    plt.plot(epochs, acc3, \"r\", label=\"Train IoU\")\n",
    "    plt.plot(epochs, val_acc3, \"r\", linestyle='dashed', label=\"Valid Iou\")\n",
    "    plt.plot(epochs, loss, \"m\", linestyle='dotted', label=\"Loss\")\n",
    "\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(\n",
    "        f\"{graph_output}\"\n",
    "    )\n",
    "    print(f\"Graph generated at : {graph_output}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # clearing up the plot the figure for next plot\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close() # clear the plot to avoid overlapping figures! https://stackoverflow.com/questions/17106288/how-to-forget-previous-plots-how-can-i-flush-refresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in files_list:\n",
    "    print(f'name is: {name}')\n",
    "    name_parts = name.split(\"_\")\n",
    "    # print(f'name is: {name_parts}')\n",
    "    city = f'{name_parts[1]}_{name_parts[2]}'\n",
    "    # print(f'city {city}')\n",
    "    name_for_graph = f'{city}_{name_parts[3]}_{name_parts[4]}'\n",
    "    name_noextension = name_for_graph.split(\".\")[0]\n",
    "    print(name_noextension)\n",
    "    \n",
    "    history_name_with_path = f'{history_dir}/{name}'\n",
    "    csv_name_with_path = f'{history_dir}/{name_noextension}.csv'\n",
    "    \n",
    "    # load the history and save to df\n",
    "    history_df=pd.read_csv(csv_name_with_path)\n",
    "\n",
    "    # plot the training and validation accuracy and loss at each epoch\n",
    "    print(\"Generating graphs ....\")\n",
    "    # graph_file_name = f'graph_{city}_bch{n_of_batches}_epc{n_of_epochs}.png'\n",
    "    graph_file_name = f'graph_{name_noextension}.png'\n",
    "    graph_output = f'{history_dir}/{graph_file_name}'\n",
    "\n",
    "    loss =  history_df.loc[:,\"loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    #---\n",
    "    acc = history_df.loc[:,\"categorical_accuracy\"]\n",
    "    val_acc = history_df.loc[:,\"val_categorical_accuracy\"]\n",
    "    acc1 = history_df.loc[:,\"recall_1\"]\n",
    "    val_acc1 = history_df.loc[:,\"val_recall_1\"]\n",
    "    acc2 = history_df.loc[:,\"precision_1\"]\n",
    "    val_acc2 = history_df.loc[:,\"val_precision_1\"]\n",
    "    acc3 = history_df.loc[:,\"ohe_iou\"]\n",
    "    val_acc3 = history_df.loc[:,\"val_ohe_iou\"]\n",
    "    # loss = history_df.loc[:,\"loss\"]\n",
    "    #---\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.plot(epochs, acc, \"y\", label=\"Train cat accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"y\", linestyle='dashed', label=\"Valid cat accuracy\")\n",
    "    plt.plot(epochs, acc1, \"b\", label=\"Train recall\")\n",
    "    plt.plot(epochs, val_acc1, \"b\", linestyle='dashed', label=\"Valid recall\")\n",
    "    plt.plot(epochs, acc2, \"c\", label=\"Train precision\")\n",
    "    plt.plot(epochs, val_acc2, \"c\", linestyle='dashed', label=\"Valid precision\")\n",
    "    plt.plot(epochs, acc3, \"r\", label=\"Train IoU\")\n",
    "    plt.plot(epochs, val_acc3, \"r\", linestyle='dashed', label=\"Valid Iou\")\n",
    "    plt.plot(epochs, loss, \"m\", linestyle='dotted', label=\"Loss\")\n",
    "\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(\n",
    "        f\"{graph_output}\"\n",
    "    )\n",
    "    print(f\"Graph generated at : {graph_output}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # clearing up the plot the figure for next plot\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close() # clear the plot to avoid overlapping figures! https://stackoverflow.com/questions/17106288/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
