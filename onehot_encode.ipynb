{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before One Hot Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color\n",
       "0    red\n",
       "1   blue\n",
       "2  green\n",
       "3   blue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After One Hot Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  blue green  red\n",
       "0  0.0   0.0  1.0\n",
       "1  1.0   0.0  0.0\n",
       "2  0.0   1.0  0.0\n",
       "3  1.0   0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "colors_df = pd.DataFrame(data=[['red'],['blue'],['green'],['blue']], columns=['color'])\n",
    "print('Before One Hot Encoding:')\n",
    "display(colors_df)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(colors_df)\n",
    "\n",
    "colors_df_encoded = one_hot_encoder.transform(colors_df)\n",
    "colors_df_encoded = pd.DataFrame(data=colors_df_encoded, columns=one_hot_encoder.categories_)\n",
    "print('\\nAfter One Hot Encoding:')\n",
    "display(colors_df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://stackoverflow.com/questions/57518057/how-can-i-convert-an-image-from-pixels-to-one-hot-encodings\n",
    "\n",
    "image_colors = [\n",
    "    (0, 0, 0),  # black\n",
    "    (127, 127, 127),  # grey\n",
    "    (255, 127, 255),  # pink\n",
    "]\n",
    "path = 'ramp-data/metric_data/onehot_source/chips/OAM-309612-261633-19.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.experimental' has no attribute 'decode_tiff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m color_reference \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mconstant(image_colors), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the image and obtain tensor with one-hot values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# image = tf.io.decode_image(tf.io.read_file(path), channels=3)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_tiff\u001b[49m()\n\u001b[1;32m      7\u001b[0m comp \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mequal(image[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, :], color_reference)\n\u001b[1;32m      8\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mreduce_all(comp, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.experimental' has no attribute 'decode_tiff'"
     ]
    }
   ],
   "source": [
    "# Create a \"color reference\" tensor from image_colors\n",
    "color_reference = tf.cast(tf.constant(image_colors), dtype=tf.uint8)\n",
    "\n",
    "# Load the image and obtain tensor with one-hot values\n",
    "image = tf.io.decode_image(tf.io.read_file(path), channels=3)\n",
    "comp = tf.equal(image[..., None, :], color_reference)\n",
    "one_hot = tf.cast(tf.reduce_all(comp, axis=-1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "categorical_labels = to_categorical(image_colors, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one more trial https://stackoverflow.com/questions/69942647/sparse-categorical-crossentropy-shape-problem-with-keras\n",
    "num_class=None\n",
    "def get_img_and_onehot_class(img_path, class):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3) # this function doens't exist for tiff files, only experimental\n",
    "    \"\"\" Other preprocessing of image.\"\"\"\n",
    "    return img, tf.one_hot(class, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tryal with actual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_chip = gdal.Open(r'ramp-data/metric_data/onehot/chips/OAM-309612-261633-19.tif') # 3 bands\n",
    "image_chip = gdal.Open(r'ramp-data/metric_data/onehot_source/chips/OAM-309606-261636-19.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_chip = to_categorical(image_chip, num_classes=None)\n",
    "# doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try convert the tif to png?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run python3 -m convert_tif_to_png --file ramp-data/metric_data/onehot_source/chips/OAM-309612-261633-19.tif\n",
    "#  we can convert to png, but in our case it wouldn't make sense, as we lose the bands info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68170720/tiff-workaround-for-tensorflow\n",
    "import cv2\n",
    "def parse_with_opencv(image_path):\n",
    "    return cv2.imread(image_path.decode('UTF-8'))\n",
    "\n",
    "img_path = [path]\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(img_path).map(\n",
    "    lambda x: tf.numpy_function(parse_with_opencv, [x], Tout=tf.uint8)\n",
    ")\n",
    "# doesn't work:\n",
    "# Unbatching a tensor is only supported for rank >= 1\n",
    "# works after adding the [] to the image path, from here:\n",
    "# https://stackoverflow.com/questions/55560620/valueerror-unbatching-a-tensor-is-only-supported-for-rank-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67969346/how-to-create-tf-dataset-from-geotiff-files-using-custom-map-function\n",
    "ds = tf.data.Dataset.from_tensor_slices([path])\n",
    "ds = ds.map(lambda x: tf.py_function(parse_image, [x], [tf.float32])).batch(8)\n",
    "# again Unbatching a tensor is only supported for rank >= 1\n",
    "# yet doesn't work with the [], we can use the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing all files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_images = \"ramp-data/metric_data/onehot_source/chips/\"\n",
    "img_list = [fille for fille in glob.glob(f'{folder_images}*.tif')]\n",
    "output_folder = \"ramp-data/metric_data/onehot/binarymasks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in img_list:\n",
    "    print(img)\n",
    "    cat_chip = to_categorical(img, num_classes=None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_chip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
