{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Import modules, variables definition, initial checks\n",
    "import sys\n",
    "sys.path\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.environ.update(os.environ)\n",
    "# Add a new environment variable to the operating system\n",
    "os.environ[\"RAMP_HOME\"] = os.getcwd()\n",
    "# Print the environment variables to verify that the new variable was added\n",
    "print(os.environ[\"RAMP_HOME\"])\n",
    "# sys.path.append('../')\n",
    "sys.path.append('ramp-code/')\n",
    "\n",
    "# used later on in the script:\n",
    "from glob import glob\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# initialise keras\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "# ramp specific\n",
    "import ramp\n",
    "\n",
    "# fair_utilities specific\n",
    "import hot_fair_utilities\n",
    "# from hot_fair_utilities import preprocess, predict, polygonize\n",
    "from hot_fair_utilities.training.cleanup import extract_highest_accuracy_model\n",
    "from hot_fair_utilities import predict\n",
    "from hot_fair_utilities import polygonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data / define variables\n",
    "list_filename =args.names_list\n",
    "\n",
    "### defining path variables\n",
    "# base_path = \"/Users/azanchetta/fAIr-utilities\" # this path is used in all the rest of the code, so change accordingly\n",
    "base_path = f\"{os.getcwd()}\"\n",
    "# base_path = \"/Users/azanchetta/fAIr_metric/\"\n",
    "print(f\"\\n---\\nCurrent working directory {base_path}\")\n",
    "\n",
    "#  --- FOR LOCAL MACHINE:\n",
    "# metric_path = \"/Users/azanchetta/fAIr_metric\"\n",
    "#  ---\n",
    "\n",
    "# check that training-datasets list file exists and is readable\n",
    "if not os.path.exists(f'{base_path}/{list_filename}'):\n",
    "    raise ValueError(f\"Can't find file {list_filename}\")\n",
    "\n",
    "### generating list of regions (cities) from the input txt file\n",
    "# input text file from command line:\n",
    "# list_filename = \"cities_list.txt\"\n",
    "\n",
    "#TO_DO: add condition of stopping if filename empty or file doesn't exist\n",
    "print(f\"---\\nI am going to get the names from {list_filename} (name of the list file you provided)\")\n",
    "# the following is to obtain the list of cities, removing commented lines (starting with \"#\"):\n",
    "with open(list_filename, 'r') as f:\n",
    "    full_file = f.read()\n",
    "    # print(full_file)\n",
    "    full_list = full_file.split('\\n') # separating per each new line\n",
    "    cities_list = []\n",
    "    for counter in range(len(full_list)):\n",
    "        line = full_list[counter]\n",
    "        # print(f\"line is {line}\")\n",
    "        if not line.startswith('#'): # this is to avoid commented lines in the input file\n",
    "            cities_list.append(full_list[counter])\n",
    "print(f\"---\\nList of cities: {cities_list}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
