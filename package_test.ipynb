{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':/home/annazan/miniconda3/envs/fair38/lib/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"LD_LIBRARY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ":/home/annazan/miniconda3/envs/fair38/lib/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ":/home/annazan/miniconda3/envs/fair38/lib/\n"
     ]
    }
   ],
   "source": [
    "!echo $LD_LIBRARY_PATH\n",
    "!source ~/.bashrc\n",
    "!echo $LD_LIBRARY_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 21:40:57.706349: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-02-13 21:40:57.706385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (buifoot): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI8nslrSgROI",
    "outputId": "2cbad97c-765f-4d2b-87df-773447500332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/annazan/fAIr-utilities\n",
      "/home/annazan/fAIr-utilities\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(os.getcwd())\n",
    "os.environ.update(os.environ)\n",
    "        # Add a new environment variable to the operating system\n",
    "os.environ[\"RAMP_HOME\"] = os.getcwd()\n",
    "# Print the environment variables to verify that the new variable was added\n",
    "print(os.environ[\"RAMP_HOME\"])\n",
    "sys.path.append('../')\n",
    "sys.path.append('../ramp-code/')\n",
    "sys.path.append('ramp-code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import ramp.utils\n",
    "import hot_fair_utilities\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/sample_2\"\n",
    "# base_path = \"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar\"\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/test_data/1_Zanzibar\"\n",
    "base_path = f'{os.getcwd()}/ramp-data/metric_data/model51_td364/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hot_fair_utilities import preprocess\n",
    "# model_input_image_path = f\"{base_path}/input\"\n",
    "# preprocess_output=f\"{base_path}/preprocessed\"\n",
    "# preprocess(\n",
    "#             input_path = model_input_image_path,\n",
    "#             output_path = preprocess_output,\n",
    "#             rasterize=True,\n",
    "#             rasterize_options=[\"binary\"],\n",
    "#             georeference_images=True,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hot_fair_utilities import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_output=f\"{base_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables are /home/annazan/fAIr-utilities/ramp-data/metric_data/model51_td364/\n",
      " and /home/annazan/fAIr-utilities/ramp-data/metric_data/model51_td364/train\n",
      "Starting to prepare data for training\n",
      "ramp home is /home/annazan/fAIr-utilities\n",
      "python home is None\n",
      "variables are: src /home/annazan/fAIr-utilities/ramp-data/metric_data/model51_td364/\n",
      " and dst:/home/annazan/fAIr-utilities/ramp-data/metric_data/model51_td364/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing /home/annazan/fAIr-utilities/ramp-data/metric_data/model51_td364/train/fair_split_train.csv\n",
      "Writing /home/annazan/fAIr-utilities/ramp-data/metric_data/model51_td364/train/fair_split_val.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done split\n",
      "Data is ready for training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'edited_constructors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m final_accuracy, final_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mramp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_home\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRAMP_HOME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/train.py:60\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_path, output_path, epoch_size, batch_size, model, model_home, freeze_layers)\u001b[0m\n\u001b[1;32m     56\u001b[0m cfg \u001b[38;5;241m=\u001b[39m manage_fine_tuning_config(\n\u001b[1;32m     57\u001b[0m     output_path, epoch_size, batch_size, freeze_layers\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is ready for training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mrun_main_train_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracting highest accuracy model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m final_accuracy, final_model_path \u001b[38;5;241m=\u001b[39m extract_highest_accuracy_model(output_path)\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/run_training.py:138\u001b[0m, in \u001b[0;36mrun_main_train_code\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    135\u001b[0m get_metrics_fn_parms \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics_fn_parms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m get_mf_name, mf_parms \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(get_metrics_fn_names, get_metrics_fn_parms):\n\u001b[0;32m--> 138\u001b[0m     get_metric_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43medited_constructors\u001b[49m, get_mf_name)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric constructor function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_metric_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m     metric_fn \u001b[38;5;241m=\u001b[39m get_metric_fn(mf_parms)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edited_constructors' is not defined"
     ]
    }
   ],
   "source": [
    "train_output = f\"{base_path}train\"\n",
    "final_accuracy, final_model_path = train(\n",
    "    input_path=preprocess_output,\n",
    "    output_path=train_output,\n",
    "    epoch_size=2,\n",
    "    batch_size=2,\n",
    "    model=\"ramp\",\n",
    "    model_home=os.environ[\"RAMP_HOME\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[here a tf file is created (weights + structure)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_accuracy,final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = f\"{os.getcwd()}/outputs/model51_td364/prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1PLe9S9BL8L",
    "outputId": "e4f3ce64-bbd6-4969-e49d-0f47dc9d6c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from hot_fair_utilities import predict\n",
    "\n",
    "\n",
    "print(f\"\\n**\\n** prediction output {prediction_output}\")\n",
    "print(f\"\\n**\\n** prediction input {base_path}prediction/input\")\n",
    "predict(\n",
    "    checkpoint_path=final_model_path,\n",
    "    input_path=f\"{base_path}prediction/input\",\n",
    "    prediction_path=prediction_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho4zn_5UBgS3",
    "outputId": "afdec49e-4172-45a6-e7b6-cd34522ca7a0"
   },
   "outputs": [],
   "source": [
    "from hot_fair_utilities import polygonize\n",
    "geojson_output= f\"{prediction_output}/prediction.geojson\"\n",
    "polygonize(\n",
    "    input_path=prediction_output, \n",
    "    output_path=geojson_output,\n",
    "    remove_inputs = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fairgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
