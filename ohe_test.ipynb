{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building from `sam_test.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/cv2/../../lib64::/home/annazan/miniconda3/envs/fair38/lib/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"LD_LIBRARY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/cv2/../../lib64::/home/annazan/miniconda3/envs/fair38/lib/\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/cv2/../../lib64::/home/annazan/miniconda3/envs/fair38/lib/\n"
     ]
    }
   ],
   "source": [
    "!echo $LD_LIBRARY_PATH\n",
    "!source ~/.bashrc\n",
    "!echo $LD_LIBRARY_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI8nslrSgROI",
    "outputId": "2cbad97c-765f-4d2b-87df-773447500332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/annazan/fAIr-utilities\n",
      "/home/annazan/fAIr-utilities\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(os.getcwd())\n",
    "os.environ.update(os.environ)\n",
    "        # Add a new environment variable to the operating system\n",
    "os.environ[\"RAMP_HOME\"] = os.getcwd()\n",
    "# Print the environment variables to verify that the new variable was added\n",
    "print(os.environ[\"RAMP_HOME\"])\n",
    "sys.path.append('../')\n",
    "sys.path.append('../ramp-code/')\n",
    "sys.path.append('ramp-code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import cv2\n",
    "import ramp.utils\n",
    "import hot_fair_utilities\n",
    "\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/sample_2\"\n",
    "# base_path = \"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar\"\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/test_data/1_Zanzibar\"\n",
    "base_path = f'{os.getcwd()}/ramp-data/test_data/model95_td370/'\n",
    "model_input_image_path = f\"{base_path}/input\"\n",
    "preprocess_output=f\"{base_path}/preprocessed\"\n",
    "train_output = f\"{base_path}/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hot_fair_utilities import preprocess\n",
    "\n",
    "# preprocess(\n",
    "#     input_path = model_input_image_path,\n",
    "#     output_path = preprocess_output,\n",
    "#     rasterize=True,\n",
    "#     # rasterize_options=[\"binary\"],\n",
    "#     rasterize_options=[\"binary\"],\n",
    "#     georeference_images=True,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make multimask path\n",
    "# !mkdir ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/\n",
    "# # Run script for multi-mask: https://github.com/kshitijrajsharma/ramp-code-fAIr/blob/ae33b11364f0a61f278ce9ff93446586704ea275/scripts/multi_masks_from_polygons.py\n",
    "# !python ramp-code/scripts/multi_masks_from_polygons.py -in_vecs ramp-data/test_data/1_Zanzibar/preprocessed/labels/ -in_chips ramp-data/test_data/1_Zanzibar/preprocessed/chips/ -out ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/ -bwidth 2 -csp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp home is /home/annazan/fAIr-utilities\n",
      "python home is None\n",
      "variables are: src /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/\n",
      " and dst:/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/fair_split_train.csv\n",
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/fair_split_val.csv\n"
     ]
    }
   ],
   "source": [
    "preprocess_output=f\"{base_path}\"\n",
    "\n",
    "from hot_fair_utilities.training.prepare_data import split_training_2_validation\n",
    "x = split_training_2_validation(preprocess_output, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from ramp.training import (\n",
    "    callback_constructors,\n",
    "    loss_constructors,\n",
    "    metric_constructors,\n",
    "    model_constructors,\n",
    "    optimizer_constructors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hot_fair_utilities.training.run_training import manage_fine_tuning_config\n",
    "\n",
    "output_path=train_output\n",
    "epoch_size=2\n",
    "batch_size=2\n",
    "freeze_layers=False\n",
    "cfg = manage_fine_tuning_config(\n",
    "            output_path, epoch_size, batch_size, freeze_layers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'experiment_name': 'HOT-OSM Efficient-Unet Finetune model_set1_batch20_epoch20_imgAug', 'discard_experiment': False, 'logging': {'log_experiment': True, 'experiment_log_path': 'ramp-data/TRAIN/fAIr-experiments.csv', 'experiment_notes': 'Binary Mask model, batchsize 20, 20 epochs on HOT-OSM dataset 1 Multizoom, finetuning from RAMP saved model', 'fields_to_log': ['experiment_name', 'experiment_notes', 'timestamp', 'num_epochs', 'batch_size', 'output_img_shape', 'input_img_shape', 'get_loss_fn_name', 'use_saved_model', 'use_aug', 'use_early_stopping', 'use_clr', 'random_seed', 'num_classes', 'get_optimizer_fn_name', 'tb_logs_dir', 'get_model_fn_name', 'backbone', 'train_img_dir', 'train_mask_dir', 'val_img_dir', 'val_mask_dir']}, 'datasets': {'train_img_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/chips', 'train_mask_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/binarymasks', 'val_img_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/val-chips', 'val_mask_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/val-binarymasks'}, 'num_classes': 2, 'num_epochs': 2, 'batch_size': 2, 'input_img_shape': [256, 256], 'output_img_shape': [256, 256], 'loss': {'get_loss_fn_name': 'get_sparse_categorical_crossentropy_fn', 'loss_fn_parms': {}}, 'metrics': {'use_metrics': True, 'get_metrics_fn_names': ['get_precision_fn'], 'metrics_fn_parms': [{}]}, 'optimizer': {'get_optimizer_fn_name': 'get_adam_optimizer', 'optimizer_fn_parms': {'learning_rate': 0.0003}}, 'model': {'get_model_fn_name': 'get_effunet_model', 'model_fn_parms': {'backbone': 'efficientnetb0', 'classes': ['background', 'buildings']}}, 'saved_model': {'use_saved_model': True, 'saved_model_path': 'ramp-code/ramp/checkpoint.tf', 'save_optimizer_state': False}, 'augmentation': {'use_aug': True, 'get_augmentation_fn_name': 'get_augmentation_fn', 'aug_list': ['Rotate', 'ColorJitter'], 'aug_parms': [{'border_mode': 'BORDER_CONSTANT', 'interpolation': 'INTER_NEAREST', 'value': [0.0, 0.0, 0.0], 'mask_value': 0, 'p': 0.7}, {'p': 0.7}]}, 'early_stopping': {'use_early_stopping': True, 'early_stopping_parms': {'monitor': 'val_loss', 'min_delta': 0.005, 'patience': 50, 'verbose': 0, 'mode': 'auto', 'restore_best_weights': False}}, 'cyclic_learning_scheduler': {'use_clr': False, 'get_clr_callback_fn_name': 'get_clr_callback_fn', 'clr_callback_parms': {'mode': 'triangular2', 'stepsize': 8, 'max_lr': 0.0001, 'base_lr': 3.25e-06}, 'clr_plot_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/plots'}, 'tensorboard': {'use_tb': True, 'tb_logs_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/logs', 'get_tb_callback_fn_name': 'get_tb_callback_fn', 'tb_callback_parms': {'histogram_freq': 1, 'update_freq': 'batch'}}, 'prediction_logging': {'use_prediction_logging': True, 'get_prediction_logging_fn_name': 'get_pred_logging_callback_fn'}, 'model_checkpts': {'use_model_checkpts': True, 'model_checkpts_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/model-checkpts', 'get_model_checkpt_callback_fn_name': 'get_model_checkpt_callback_fn', 'model_checkpt_callback_parms': {'mode': 'max', 'save_best_only': True}}, 'feedback': {'freeze_layers': False}, 'random_seed': 20220523, 'freeze_layers': False, 'graph_location': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/graphs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Config:\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_experiment = False\n",
    "if \"discard_experiment\" in cfg:\n",
    "    discard_experiment = cfg[\"discard_experiment\"]\n",
    "cfg[\"timestamp\"] = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric constructor function: get_iou_fn\n",
      "Loss constructor functions: get_categorical_crossentropy_fn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "the_metrics = []\n",
    "if cfg[\"metrics\"][\"use_metrics\"]:\n",
    "    get_metrics_fn_names = cfg[\"metrics\"][\"get_metrics_fn_names\"]\n",
    "    get_metrics_fn_parms = cfg[\"metrics\"][\"metrics_fn_parms\"]\n",
    "    assert len(get_metrics_fn_names) == len(get_metrics_fn_parms)\n",
    "    \n",
    "    \n",
    "    #---\n",
    "    # TODO: manually changing here for OHE experiment\n",
    "    # get_metrics_fn_names = [\"get_precision_fn\", \"get_iou_fn\"]\n",
    "    # get_metrics_fn_names = [\"get_sparse_categorical_accuracy_fn\", \"get_precision_fn\", \"get_iou_fn\", \"get_recall_fn\"]\n",
    "    get_metrics_fn_names = [\"get_precision_fn\"]\n",
    "    get_metrics_fn_parms = [{}]\n",
    "    #---\n",
    "    for get_mf_name, mf_parms in zip(get_metrics_fn_names, get_metrics_fn_parms):\n",
    "        \n",
    "        get_metric_fn = getattr(metric_constructors, get_mf_name)\n",
    "        print(f\"Metric constructor function: {get_metric_fn.__name__}\")\n",
    "        metric_fn = get_metric_fn(mf_parms)\n",
    "        the_metrics.append(metric_fn)\n",
    "\n",
    "# specify a function that will construct the loss function\n",
    "get_loss_fn_name = cfg[\"loss\"][\"get_loss_fn_name\"]\n",
    "\n",
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "# get_loss_fn_name = [\"get_sparse_categorical_crossentropy_fn\", \"get_categorical_crossentropy_fn\"]\n",
    "# get_loss_fn_parms = [{}, {}]\n",
    "get_loss_fn_name = [\"get_categorical_crossentropy_fn\"]\n",
    "get_loss_fn_parms = [{}]\n",
    "# ---\n",
    "\n",
    "# get_loss_fn = getattr(loss_constructors, get_loss_fn_name)\n",
    "# # Construct the loss function\n",
    "# loss_fn = get_loss_fn(cfg)\n",
    "\n",
    "# print(f\"Loss constructor function: {get_loss_fn.__name__}\")\n",
    "\n",
    "the_losses = []\n",
    "for get_lf_name, lf_parms in zip(get_loss_fn_name, get_loss_fn_parms):\n",
    "    \n",
    "    get_loss_fn = getattr(loss_constructors, get_lf_name)\n",
    "    print(f\"Loss constructor functions: {get_loss_fn.__name__}\")\n",
    "    loss_fn = get_loss_fn(lf_parms)\n",
    "    the_losses.append(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: importing saved model /home/annazan/fAIr-utilities/ramp-code/ramp/checkpoint.tf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "-------[<keras.metrics.metrics.IoU object at 0x7f9f247372e0>]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#### construct optimizer ####\n",
    "get_optimizer_fn_name = cfg[\"optimizer\"][\"get_optimizer_fn_name\"]\n",
    "get_optimizer_fn = getattr(optimizer_constructors, get_optimizer_fn_name)\n",
    "\n",
    "optimizer = get_optimizer_fn(cfg)\n",
    "\n",
    "the_model = None\n",
    "\n",
    "# SG: Using the saved model in this cell\n",
    "working_ramp_home = os.environ[\"RAMP_HOME\"]\n",
    "# load (construct) the model\n",
    "model_path = Path(working_ramp_home) / cfg[\"saved_model\"][\"saved_model_path\"]\n",
    "print(f\"Model: importing saved model {str(model_path)}\")\n",
    "the_model = tf.keras.models.load_model(model_path)\n",
    "assert (\n",
    "    the_model is not None\n",
    "), f\"the saved model was not constructed: {model_path}\"\n",
    "\n",
    "if cfg[\"freeze_layers\"]:\n",
    "    for layer in the_model.layers:\n",
    "        layer.trainable = False  # freeze previous layers only update new layers\n",
    "        # print(\"Setting previous model layers traininable : False\")\n",
    "\n",
    "\n",
    "print(\"-------\")\n",
    "print(f'-------{the_metrics}')\n",
    "print(\"-------\")\n",
    "\n",
    "# If you don't want to save the original state of training, recompile the model.\n",
    "the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[the_metrics])\n",
    "# the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[precision_class_0,precision_class_1])\n",
    "\n",
    "# the_model.compile(optimizer = optimizer,\n",
    "#    loss=loss_fn,\n",
    "#    metrics = [get_iou_coef_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.609438>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of non-sparse loss fn with probs over labels and OHE labels (total 4 classes)\n",
    "y_true = tf.one_hot([0, 1], depth=4, axis=-1)\n",
    "y_pred = [[0.05, 0.95, 0, 0], [0.1, 0.8, 0.1, 0]]\n",
    "loss_fn(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.05, 0.95, 0, 0], [0.1, 0.8, 0.1, 0]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss constructor function: <keras.losses.CategoricalCrossentropy object at 0x7f9f24737bb0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss constructor function: {loss_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.609438>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model summary:\")\n",
    "# print(the_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "def ohe_batches(batches: tf.data.Dataset, depth=4) -> tf.data.Dataset:\n",
    "    \"\"\"For given batches and depth map sparse labels to OHE.\"\"\"\n",
    "    return batches.map(lambda x, y: (x, tf.one_hot(y[..., -1], depth, axis=-1)))\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "* train img dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/chips\n",
      "* train mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/binarymasks\n",
      "* input img shape[256, 256]\n",
      "* output img shape[256, 256]\n",
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "from ramp.training.augmentation_constructors import get_augmentation_fn\n",
    "from ramp.utils.misc_ramp_utils import get_num_files\n",
    "from ramp.data_mgmt.data_generator import (\n",
    "    test_batches_from_gtiff_dirs,\n",
    "    training_batches_from_gtiff_dirs,\n",
    ")\n",
    "#### define data directories ####\n",
    "train_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_img_dir\"]\n",
    "train_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_mask_dir\"]\n",
    "val_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_img_dir\"]\n",
    "val_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_mask_dir\"]\n",
    "\n",
    "#### get the augmentation transform ####\n",
    "# aug = None\n",
    "if cfg[\"augmentation\"][\"use_aug\"]:\n",
    "    aug = get_augmentation_fn(cfg)\n",
    "\n",
    "## RUNTIME Parameters\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "input_img_shape = cfg[\"input_img_shape\"]\n",
    "output_img_shape = cfg[\"output_img_shape\"]\n",
    "\n",
    "n_training = get_num_files(train_img_dir, \"*.tif\")\n",
    "n_val = get_num_files(val_img_dir, \"*.tif\")\n",
    "steps_per_epoch = n_training // batch_size\n",
    "validation_steps = n_val // batch_size\n",
    "# Testing step , not recommended\n",
    "if validation_steps <= 0:\n",
    "    validation_steps = 1\n",
    "\n",
    "# add these back to the config\n",
    "# in case they are needed by callbacks\n",
    "cfg[\"runtime\"] = {}\n",
    "cfg[\"runtime\"][\"n_training\"] = n_training\n",
    "cfg[\"runtime\"][\"n_val\"] = n_val\n",
    "cfg[\"runtime\"][\"steps_per_epoch\"] = steps_per_epoch\n",
    "cfg[\"runtime\"][\"validation_steps\"] = validation_steps\n",
    "\n",
    "train_batches = None\n",
    "\n",
    "if aug is not None:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir,\n",
    "        train_mask_dir,\n",
    "        batch_size,\n",
    "        input_img_shape,\n",
    "        output_img_shape,\n",
    "        transforms=aug,\n",
    "    )\n",
    "else:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir, train_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "    )\n",
    "assert train_batches is not None, \"training batches were not constructed\"\n",
    "print(f\"-------\\n* train img dir{train_img_dir}\\n* train mask dir{train_mask_dir}\")\n",
    "print(f\"* input img shape{input_img_shape}\\n* output img shape{output_img_shape}\")\n",
    "\n",
    "\n",
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "train_batches = ohe_batches(train_batches)\n",
    "#---\n",
    "print(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Batches are a tf.data.Dataset type\n",
    "print(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a single batch as numpy to explore\n",
    "iter = tf.data.Dataset.as_numpy_iterator(train_batches)\n",
    "(X_batch, y_true_batch) = iter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for elem in iter:\n",
    "#   print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524288"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_true_batch.size # 524288\n",
    "# y_true_batch.itemsize # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393216"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.size # 393216\n",
    "# X_batch.itemsize # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_batch[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is: 2\n",
      "Example X entry: [0.0664828 0.0664828 0.0664828]\n",
      "Input data shape (X): (2, 256, 256, 3)\n",
      "Ground truth data shape (y_true): (2, 256, 256, 4)\n",
      "Example y_true:  [0. 1. 0. 0.]\n",
      "The unique labels in the y_true: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Print useful info\n",
    "print(\"Batch size is:\", X_batch.shape[0])\n",
    "# Appears to be floats between 0 and 1\n",
    "print(\"Example X entry:\", X_batch[0, 0, 0, :])\n",
    "print(\"Input data shape (X):\", X_batch.shape)\n",
    "print(\"Ground truth data shape (y_true):\", y_true_batch.shape)\n",
    "print(\"Example y_true: \", y_true_batch[1, 0, 0, :])\n",
    "print(f\"The unique labels in the y_true: {np.unique(y_true_batch[0, :, :, 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 967ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get some predictions from the model for the batch\n",
    "y_pred_batch = the_model.predict(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions y_pred_batch are: (2, 256, 256, 4)\n"
     ]
    }
   ],
   "source": [
    "# Shape of output predictions\n",
    "print(\"Predictions y_pred_batch are:\", y_pred_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9677142  0.00155651 0.0297472  0.00098208]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example single pixel prediction\n",
    "single_prediction = y_pred_batch[0, 0, 0, :]\n",
    "print(single_prediction)\n",
    "\n",
    "# Single prediction sums to 1: probabilties over the four categories of the model\n",
    "single_prediction.sum().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.2069845>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.loss(y_true_batch, y_pred_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "* val img dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/val-chips\n",
      "* val mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/val-binarymasks\n",
      "-------\n",
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float32, name=None))>\n",
      "*\n",
      "*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation batches\n",
    "val_batches = test_batches_from_gtiff_dirs(\n",
    "    val_img_dir, val_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    ")\n",
    "\n",
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "val_batches = ohe_batches(val_batches)\n",
    "#---\n",
    "\n",
    "assert val_batches is not None, \"validation batches were not constructed\"\n",
    "print(f\"-------\\n* val img dir{val_img_dir}\\n* val mask dir{val_mask_dir}\\n-------\")\n",
    "print(val_batches)\n",
    "print('*\\n*\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "# ---------------\n",
    "## Callbacks ##\n",
    "callbacks_list = []\n",
    "\n",
    "if not discard_experiment:\n",
    "    # get model checkpoint callback\n",
    "    if cfg[\"model_checkpts\"][\"use_model_checkpts\"]:\n",
    "        get_model_checkpt_callback_fn_name = cfg[\"model_checkpts\"][\n",
    "            \"get_model_checkpt_callback_fn_name\"\n",
    "        ]\n",
    "        get_model_checkpt_callback_fn = getattr(\n",
    "            callback_constructors, get_model_checkpt_callback_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_model_checkpt_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard callback\n",
    "    if cfg[\"tensorboard\"][\"use_tb\"]:\n",
    "        get_tb_callback_fn_name = cfg[\"tensorboard\"][\"get_tb_callback_fn_name\"]\n",
    "        get_tb_callback_fn = getattr(callback_constructors, get_tb_callback_fn_name)\n",
    "        callbacks_list.append(get_tb_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard model prediction logging callback\n",
    "    if cfg[\"prediction_logging\"][\"use_prediction_logging\"]:\n",
    "        assert cfg[\"tensorboard\"][\n",
    "            \"use_tb\"\n",
    "        ], \"Tensorboard logging must be turned on to enable prediction logging\"\n",
    "        get_prediction_logging_fn_name = cfg[\"prediction_logging\"][\n",
    "            \"get_prediction_logging_fn_name\"\n",
    "        ]\n",
    "        get_prediction_logging_fn = getattr(\n",
    "            callback_constructors, get_prediction_logging_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_prediction_logging_fn(the_model, cfg))\n",
    "\n",
    "# free up RAM\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "if cfg[\"early_stopping\"][\"use_early_stopping\"]:\n",
    "    callbacks_list.append(callback_constructors.get_early_stopping_callback_fn(cfg))\n",
    "\n",
    "    # get cyclic learning scheduler callback\n",
    "if cfg[\"cyclic_learning_scheduler\"][\"use_clr\"]:\n",
    "    assert not cfg[\"early_stopping\"][\n",
    "        \"use_early_stopping\"\n",
    "    ], \"cannot use early_stopping with cycling_learning_scheduler\"\n",
    "    get_clr_callback_fn_name = cfg[\"cyclic_learning_scheduler\"][\n",
    "        \"get_clr_callback_fn_name\"\n",
    "    ]\n",
    "    get_clr_callback_fn = getattr(callback_constructors, get_clr_callback_fn_name)\n",
    "    callbacks_list.append(get_clr_callback_fn(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/model-checkpts/20240311-210255/model_20240311-210255_{epoch:03d}_{val_precision_1:.3f}.tf'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call = callbacks_list[0]\n",
    "call.filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with 10 epochs , 2 batch size , 71 steps per epoch , 12 validation steps......\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - ETA: 0s - loss: 0.8313 - iou: 0.4412"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Failed to format this callback filepath: \"/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/model-checkpts/20240311-210255/model_20240311-210255_{epoch:03d}_{val_precision_1:.3f}.tf\". Reason: \\'val_precision_1\\''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# FIXME : Make checkpoint\u001b[39;00m\n\u001b[1;32m     16\u001b[0m start \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mthe_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m end \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Finished , Time taken to train : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/callbacks.py:1487\u001b[0m, in \u001b[0;36mModelCheckpoint._get_file_path\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1485\u001b[0m         epoch\u001b[38;5;241m=\u001b[39mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, batch\u001b[38;5;241m=\u001b[39mbatch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlogs)\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1487\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1488\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to format this callback filepath: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1489\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReason: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_filepath \u001b[38;5;241m=\u001b[39m distributed_file_utils\u001b[38;5;241m.\u001b[39mwrite_filepath(\n\u001b[1;32m   1491\u001b[0m     file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_filepath\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Failed to format this callback filepath: \"/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/model-checkpts/20240311-210255/model_20240311-210255_{epoch:03d}_{val_precision_1:.3f}.tf\". Reason: \\'val_precision_1\\''"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "\n",
    "## Main training block ##\n",
    "n_epochs = cfg[\"num_epochs\"]\n",
    "# SG: manually make this 10\n",
    "n_epochs = 10\n",
    "print(\n",
    "    f\"Starting Training with {n_epochs} epochs , {batch_size} batch size , {steps_per_epoch} steps per epoch , {validation_steps} validation steps......\"\n",
    ")\n",
    "if validation_steps <= 0:\n",
    "    raise RaiseError(\n",
    "        \"Not enough data for training, Increase image or Try reducing batchsize/epochs\"\n",
    "    )\n",
    "# FIXME : Make checkpoint\n",
    "start = perf_counter()\n",
    "history = the_model.fit(\n",
    "    train_batches,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_batches,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list,\n",
    ")\n",
    "end = perf_counter()\n",
    "print(f\"Training Finished , Time taken to train : {end-start} seconds\")\n",
    "print('\\n-----\\nHistory:')\n",
    "print(history.history.keys())\n",
    "print('\\n-----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the training and validation accuracy and loss at each epoch\n",
    "print(\"Generating graphs ....\")\n",
    "if not os.path.exists(cfg[\"graph_location\"]):\n",
    "    os.mkdir(cfg[\"graph_location\"])\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "# val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "#---\n",
    "# TODO: updated for OHE\n",
    "acc = history.history[\"precision_1\"]\n",
    "val_acc = history.history[\"val_precision_1\"]\n",
    "#---\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    f\"{cfg['graph_location']}/training_validation_sparse_categorical_accuracy.png\"\n",
    ")\n",
    "print(f\"Graph generated at : {cfg['graph_location']}\")\n",
    "print(f\"accuracy {acc}\")\n",
    "print(f\"accuracy {val_acc}\")\n",
    "print(f\"loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "print(history.history[\"val_iou\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # APPENDIX: from copying across\n",
    "\n",
    "# #### construct optimizer ####\n",
    "# get_optimizer_fn_name = cfg[\"optimizer\"][\"get_optimizer_fn_name\"]\n",
    "# get_optimizer_fn = getattr(optimizer_constructors, get_optimizer_fn_name)\n",
    "\n",
    "# optimizer = get_optimizer_fn(cfg)\n",
    "\n",
    "# the_model = None\n",
    "\n",
    "# if cfg[\"saved_model\"][\"use_saved_model\"]:\n",
    "#     # load (construct) the model\n",
    "#     model_path = Path(working_ramp_home) / cfg[\"saved_model\"][\"saved_model_path\"]\n",
    "#     print(f\"Model: importing saved model {str(model_path)}\")\n",
    "#     the_model = tf.keras.models.load_model(model_path)\n",
    "#     assert (\n",
    "#         the_model is not None\n",
    "#     ), f\"the saved model was not constructed: {model_path}\"\n",
    "\n",
    "#     if cfg[\"freeze_layers\"]:\n",
    "#         for layer in the_model.layers:\n",
    "#             layer.trainable = False  # freeze previous layers only update new layers\n",
    "#             # print(\"Setting previous model layers traininable : False\")\n",
    "\n",
    "#     if not cfg[\"saved_model\"][\"save_optimizer_state\"]:\n",
    "#         print(\"-------\")\n",
    "#         print(f'-------{the_metrics}')\n",
    "#         print(\"-------\")\n",
    "        \n",
    "#         # For class 0\n",
    "#         precision_class_0 = Precision(class_id=0)\n",
    "#         # For class 1\n",
    "#         precision_class_1 = Precision(class_id=1)\n",
    "#         metrics=[precision_class_0,precision_class_1]\n",
    "#         print(f'-------{the_metrics}')\n",
    "#         print(\"-------\")\n",
    "        \n",
    "#         # If you don't want to save the original state of training, recompile the model.\n",
    "#         the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[the_metrics])\n",
    "#         # the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[precision_class_0,precision_class_1])\n",
    "        \n",
    "#         # the_model.compile(optimizer = optimizer,\n",
    "#         #    loss=loss_fn,\n",
    "#         #    metrics = [get_iou_coef_fn])\n",
    "\n",
    "# if not cfg[\"saved_model\"][\"use_saved_model\"]:\n",
    "#     get_model_fn_name = cfg[\"model\"][\"get_model_fn_name\"]\n",
    "#     get_model_fn = getattr(model_constructors, get_model_fn_name)\n",
    "#     the_model = get_model_fn(cfg)\n",
    "\n",
    "#     assert the_model is not None, f\"the model was not constructed: {model_path}\"\n",
    "#     the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=the_metrics)\n",
    "\n",
    "# print(the_model)\n",
    "# cfg[\"datasets\"]\n",
    "\n",
    "# #### define data directories ####\n",
    "# train_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_img_dir\"]\n",
    "# train_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_mask_dir\"]\n",
    "# val_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_img_dir\"]\n",
    "# val_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_mask_dir\"]\n",
    "\n",
    "# #### get the augmentation transform ####\n",
    "# # aug = None\n",
    "# if cfg[\"augmentation\"][\"use_aug\"]:\n",
    "#     aug = get_augmentation_fn(cfg)\n",
    "\n",
    "# ## RUNTIME Parameters\n",
    "# batch_size = cfg[\"batch_size\"]\n",
    "# input_img_shape = cfg[\"input_img_shape\"]\n",
    "# output_img_shape = cfg[\"output_img_shape\"]\n",
    "\n",
    "# n_training = get_num_files(train_img_dir, \"*.tif\")\n",
    "# n_val = get_num_files(val_img_dir, \"*.tif\")\n",
    "# steps_per_epoch = n_training // batch_size\n",
    "# validation_steps = n_val // batch_size\n",
    "# # Testing step , not recommended\n",
    "# if validation_steps <= 0:\n",
    "#     validation_steps = 1\n",
    "\n",
    "# # add these back to the config\n",
    "# # in case they are needed by callbacks\n",
    "# cfg[\"runtime\"] = {}\n",
    "# cfg[\"runtime\"][\"n_training\"] = n_training\n",
    "# cfg[\"runtime\"][\"n_val\"] = n_val\n",
    "# cfg[\"runtime\"][\"steps_per_epoch\"] = steps_per_epoch\n",
    "# cfg[\"runtime\"][\"validation_steps\"] = validation_steps\n",
    "\n",
    "# train_batches = None\n",
    "\n",
    "# if aug is not None:\n",
    "#     train_batches = training_batches_from_gtiff_dirs(\n",
    "#         train_img_dir,\n",
    "#         train_mask_dir,\n",
    "#         batch_size,\n",
    "#         input_img_shape,\n",
    "#         output_img_shape,\n",
    "#         transforms=aug,\n",
    "#     )\n",
    "# else:\n",
    "#     train_batches = training_batches_from_gtiff_dirs(\n",
    "#         train_img_dir, train_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "#     )\n",
    "\n",
    "# assert train_batches is not None, \"training batches were not constructed\"\n",
    "# print(f\"-------\\n* train img dir{train_img_dir}\\n* train mask dir{train_mask_dir}\")\n",
    "# print(f\"* input img shape{input_img_shape}\\n* output img shape{output_img_shape}\")\n",
    "\n",
    "# print(train_batches)\n",
    "\n",
    "# val_batches = test_batches_from_gtiff_dirs(\n",
    "#     val_img_dir, val_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "# )\n",
    "\n",
    "# assert val_batches is not None, \"validation batches were not constructed\"\n",
    "# print(f\"-------\\n* val img dir{val_img_dir}\\n* val mask dir{val_mask_dir}\\n-------\")\n",
    "# print(val_batches)\n",
    "# print('*\\n*\\n')\n",
    "\n",
    "# ## Callbacks ##\n",
    "# callbacks_list = []\n",
    "\n",
    "# if not discard_experiment:\n",
    "#     # get model checkpoint callback\n",
    "#     if cfg[\"model_checkpts\"][\"use_model_checkpts\"]:\n",
    "#         get_model_checkpt_callback_fn_name = cfg[\"model_checkpts\"][\n",
    "#             \"get_model_checkpt_callback_fn_name\"\n",
    "#         ]\n",
    "#         get_model_checkpt_callback_fn = getattr(\n",
    "#             callback_constructors, get_model_checkpt_callback_fn_name\n",
    "#         )\n",
    "#         callbacks_list.append(get_model_checkpt_callback_fn(cfg))\n",
    "\n",
    "#     # get tensorboard callback\n",
    "#     if cfg[\"tensorboard\"][\"use_tb\"]:\n",
    "#         get_tb_callback_fn_name = cfg[\"tensorboard\"][\"get_tb_callback_fn_name\"]\n",
    "#         get_tb_callback_fn = getattr(callback_constructors, get_tb_callback_fn_name)\n",
    "#         callbacks_list.append(get_tb_callback_fn(cfg))\n",
    "\n",
    "#     # get tensorboard model prediction logging callback\n",
    "#     if cfg[\"prediction_logging\"][\"use_prediction_logging\"]:\n",
    "#         assert cfg[\"tensorboard\"][\n",
    "#             \"use_tb\"\n",
    "#         ], \"Tensorboard logging must be turned on to enable prediction logging\"\n",
    "#         get_prediction_logging_fn_name = cfg[\"prediction_logging\"][\n",
    "#             \"get_prediction_logging_fn_name\"\n",
    "#         ]\n",
    "#         get_prediction_logging_fn = getattr(\n",
    "#             callback_constructors, get_prediction_logging_fn_name\n",
    "#         )\n",
    "#         callbacks_list.append(get_prediction_logging_fn(the_model, cfg))\n",
    "\n",
    "# # free up RAM\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# if cfg[\"early_stopping\"][\"use_early_stopping\"]:\n",
    "#     callbacks_list.append(callback_constructors.get_early_stopping_callback_fn(cfg))\n",
    "\n",
    "#     # get cyclic learning scheduler callback\n",
    "# if cfg[\"cyclic_learning_scheduler\"][\"use_clr\"]:\n",
    "#     assert not cfg[\"early_stopping\"][\n",
    "#         \"use_early_stopping\"\n",
    "#     ], \"cannot use early_stopping with cycling_learning_scheduler\"\n",
    "#     get_clr_callback_fn_name = cfg[\"cyclic_learning_scheduler\"][\n",
    "#         \"get_clr_callback_fn_name\"\n",
    "#     ]\n",
    "#     get_clr_callback_fn = getattr(callback_constructors, get_clr_callback_fn_name)\n",
    "#     callbacks_list.append(get_clr_callback_fn(cfg))\n",
    "\n",
    "# ## Main training block ##\n",
    "# n_epochs = cfg[\"num_epochs\"]\n",
    "# print(\n",
    "#     f\"Starting Training with {n_epochs} epochs , {batch_size} batch size , {steps_per_epoch} steps per epoch , {validation_steps} validation steps......\"\n",
    "# )\n",
    "# if validation_steps <= 0:\n",
    "#     raise RaiseError(\n",
    "#         \"Not enough data for training, Increase image or Try reducing batchsize/epochs\"\n",
    "#     )\n",
    "# # FIXME : Make checkpoint\n",
    "# start = perf_counter()\n",
    "# history = the_model.fit(\n",
    "#     train_batches,\n",
    "#     epochs=n_epochs,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_data=val_batches,\n",
    "#     validation_steps=validation_steps,\n",
    "#     callbacks=callbacks_list,\n",
    "# )\n",
    "# end = perf_counter()\n",
    "# print(f\"Training Finished , Time taken to train : {end-start} seconds\")\n",
    "# print('\\n-----\\nHistory:')\n",
    "# print(history.history.keys())\n",
    "# print('\\n-----')\n",
    "\n",
    "# # plot the training and validation accuracy and loss at each epoch\n",
    "# print(\"Generating graphs ....\")\n",
    "# if not os.path.exists(cfg[\"graph_location\"]):\n",
    "#     os.mkdir(cfg[\"graph_location\"])\n",
    "\n",
    "# loss = history.history[\"loss\"]\n",
    "# # val_loss = history.history[\"val_loss\"]\n",
    "# epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "# val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "# # Plot training and validation accuracy\n",
    "# plt.plot(epochs, acc, \"y\", label=\"Training Accuracy\")\n",
    "# plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
    "\n",
    "# # Set labels and title\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig(\n",
    "#     f\"{cfg['graph_location']}/training_validation_sparse_categorical_accuracy.png\"\n",
    "# )\n",
    "# print(f\"Graph generated at : {cfg['graph_location']}\")\n",
    "# print(f\"accuracy {acc}\")\n",
    "# print(f\"accuracy {val_acc}\")\n",
    "# print(f\"loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/fair_split_train.csv\")\n",
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hot_fair_utilities import train\n",
    "train_output = f\"{base_path}train\"\n",
    "final_accuracy, final_model_path = train(\n",
    "    input_path=preprocess_output,\n",
    "    output_path=train_output,\n",
    "    epoch_size=2,\n",
    "    batch_size=2,\n",
    "    model=\"ramp\",\n",
    "    model_home=os.environ[\"RAMP_HOME\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[here a tf file is created (weights + structure)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_accuracy,final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = f\"{os.getcwd()}/outputs/model51_td364/prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1PLe9S9BL8L",
    "outputId": "e4f3ce64-bbd6-4969-e49d-0f47dc9d6c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from hot_fair_utilities import predict\n",
    "\n",
    "\n",
    "print(f\"\\n**\\n** prediction output {prediction_output}\")\n",
    "print(f\"\\n**\\n** prediction input {base_path}prediction/input\")\n",
    "predict(\n",
    "    checkpoint_path=final_model_path,\n",
    "    input_path=f\"{base_path}prediction/input\",\n",
    "    prediction_path=prediction_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho4zn_5UBgS3",
    "outputId": "afdec49e-4172-45a6-e7b6-cd34522ca7a0"
   },
   "outputs": [],
   "source": [
    "from hot_fair_utilities import polygonize\n",
    "geojson_output= f\"{prediction_output}/prediction.geojson\"\n",
    "polygonize(\n",
    "    input_path=prediction_output, \n",
    "    output_path=geojson_output,\n",
    "    remove_inputs = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fairgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
