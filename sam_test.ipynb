{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/annazan/miniconda3/envs/fair38/lib/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"LD_LIBRARY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ":/home/annazan/miniconda3/envs/fair38/lib/\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ":/home/annazan/miniconda3/envs/fair38/lib/\n"
     ]
    }
   ],
   "source": [
    "!echo $LD_LIBRARY_PATH\n",
    "!source ~/.bashrc\n",
    "!echo $LD_LIBRARY_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI8nslrSgROI",
    "outputId": "2cbad97c-765f-4d2b-87df-773447500332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/annazan/fAIr-utilities\n",
      "/home/annazan/fAIr-utilities\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(os.getcwd())\n",
    "os.environ.update(os.environ)\n",
    "        # Add a new environment variable to the operating system\n",
    "os.environ[\"RAMP_HOME\"] = os.getcwd()\n",
    "# Print the environment variables to verify that the new variable was added\n",
    "print(os.environ[\"RAMP_HOME\"])\n",
    "sys.path.append('../')\n",
    "sys.path.append('../ramp-code/')\n",
    "sys.path.append('ramp-code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import cv2\n",
    "import ramp.utils\n",
    "import hot_fair_utilities\n",
    "\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/sample_2\"\n",
    "# base_path = \"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar\"\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/test_data/1_Zanzibar\"\n",
    "base_path = f'{os.getcwd()}/ramp-data/test_data/model95_td370/'\n",
    "model_input_image_path = f\"{base_path}/input\"\n",
    "preprocess_output=f\"{base_path}/preprocessed\"\n",
    "train_output = f\"{base_path}/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hot_fair_utilities import preprocess\n",
    "\n",
    "# preprocess(\n",
    "#     input_path = model_input_image_path,\n",
    "#     output_path = preprocess_output,\n",
    "#     rasterize=True,\n",
    "#     # rasterize_options=[\"binary\"],\n",
    "#     rasterize_options=[\"binary\"],\n",
    "#     georeference_images=True,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "mkdir: cannot create directory ‘ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/’: File exists\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Input polygons directory: ramp-data/test_data/1_Zanzibar/preprocessed/labels/\n",
      "Input matching image chips directory: ramp-data/test_data/1_Zanzibar/preprocessed/chips/\n",
      "Output multichannel masks directory: ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/\n",
      "Boundary mask boundary width: 2\n",
      "Contact mask contact spacing: 4\n",
      "10it [00:00, 73071.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Make multimask path\n",
    "# !mkdir ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/\n",
    "# # Run script for multi-mask: https://github.com/kshitijrajsharma/ramp-code-fAIr/blob/ae33b11364f0a61f278ce9ff93446586704ea275/scripts/multi_masks_from_polygons.py\n",
    "# !python ramp-code/scripts/multi_masks_from_polygons.py -in_vecs ramp-data/test_data/1_Zanzibar/preprocessed/labels/ -in_chips ramp-data/test_data/1_Zanzibar/preprocessed/chips/ -out ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/ -bwidth 2 -csp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp home is /home/annazan/fAIr-utilities\n",
      "python home is None\n",
      "variables are: src /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/\n",
      " and dst:/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/fair_split_train.csv\n",
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/fair_split_val.csv\n"
     ]
    }
   ],
   "source": [
    "preprocess_output=f\"{base_path}\"\n",
    "\n",
    "from hot_fair_utilities.training.prepare_data import split_training_2_validation\n",
    "x = split_training_2_validation(preprocess_output, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from ramp.training import (\n",
    "    callback_constructors,\n",
    "    loss_constructors,\n",
    "    metric_constructors,\n",
    "    model_constructors,\n",
    "    optimizer_constructors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hot_fair_utilities.training.run_training import manage_fine_tuning_config\n",
    "\n",
    "output_path=train_output\n",
    "epoch_size=2\n",
    "batch_size=2\n",
    "freeze_layers=False\n",
    "cfg = manage_fine_tuning_config(\n",
    "            output_path, epoch_size, batch_size, freeze_layers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'HOT-OSM Efficient-Unet Finetune model_set1_batch20_epoch20_imgAug',\n",
       " 'discard_experiment': False,\n",
       " 'logging': {'log_experiment': True,\n",
       "  'experiment_log_path': 'ramp-data/TRAIN/fAIr-experiments.csv',\n",
       "  'experiment_notes': 'Binary Mask model, batchsize 20, 20 epochs on HOT-OSM dataset 1 Multizoom, finetuning from RAMP saved model',\n",
       "  'fields_to_log': ['experiment_name',\n",
       "   'experiment_notes',\n",
       "   'timestamp',\n",
       "   'num_epochs',\n",
       "   'batch_size',\n",
       "   'output_img_shape',\n",
       "   'input_img_shape',\n",
       "   'get_loss_fn_name',\n",
       "   'use_saved_model',\n",
       "   'use_aug',\n",
       "   'use_early_stopping',\n",
       "   'use_clr',\n",
       "   'random_seed',\n",
       "   'num_classes',\n",
       "   'get_optimizer_fn_name',\n",
       "   'tb_logs_dir',\n",
       "   'get_model_fn_name',\n",
       "   'backbone',\n",
       "   'train_img_dir',\n",
       "   'train_mask_dir',\n",
       "   'val_img_dir',\n",
       "   'val_mask_dir']},\n",
       " 'datasets': {'train_img_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/chips',\n",
       "  'train_mask_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/binarymasks',\n",
       "  'val_img_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/val-chips',\n",
       "  'val_mask_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/val-binarymasks'},\n",
       " 'num_classes': 2,\n",
       " 'num_epochs': 2,\n",
       " 'batch_size': 2,\n",
       " 'input_img_shape': [256, 256],\n",
       " 'output_img_shape': [256, 256],\n",
       " 'loss': {'get_loss_fn_name': 'get_sparse_categorical_crossentropy_fn',\n",
       "  'loss_fn_parms': {}},\n",
       " 'metrics': {'use_metrics': True,\n",
       "  'get_metrics_fn_names': ['get_sparse_categorical_accuracy_fn'],\n",
       "  'metrics_fn_parms': [{}]},\n",
       " 'optimizer': {'get_optimizer_fn_name': 'get_adam_optimizer',\n",
       "  'optimizer_fn_parms': {'learning_rate': 0.0003}},\n",
       " 'model': {'get_model_fn_name': 'get_effunet_model',\n",
       "  'model_fn_parms': {'backbone': 'efficientnetb0',\n",
       "   'classes': ['background', 'buildings']}},\n",
       " 'saved_model': {'use_saved_model': True,\n",
       "  'saved_model_path': 'ramp-code/ramp/checkpoint.tf',\n",
       "  'save_optimizer_state': False},\n",
       " 'augmentation': {'use_aug': True,\n",
       "  'get_augmentation_fn_name': 'get_augmentation_fn',\n",
       "  'aug_list': ['Rotate', 'ColorJitter'],\n",
       "  'aug_parms': [{'border_mode': 'BORDER_CONSTANT',\n",
       "    'interpolation': 'INTER_NEAREST',\n",
       "    'value': [0.0, 0.0, 0.0],\n",
       "    'mask_value': 0,\n",
       "    'p': 0.7},\n",
       "   {'p': 0.7}]},\n",
       " 'early_stopping': {'use_early_stopping': True,\n",
       "  'early_stopping_parms': {'monitor': 'val_loss',\n",
       "   'min_delta': 0.005,\n",
       "   'patience': 50,\n",
       "   'verbose': 0,\n",
       "   'mode': 'auto',\n",
       "   'restore_best_weights': False}},\n",
       " 'cyclic_learning_scheduler': {'use_clr': False,\n",
       "  'get_clr_callback_fn_name': 'get_clr_callback_fn',\n",
       "  'clr_callback_parms': {'mode': 'triangular2',\n",
       "   'stepsize': 8,\n",
       "   'max_lr': 0.0001,\n",
       "   'base_lr': 3.25e-06},\n",
       "  'clr_plot_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/plots'},\n",
       " 'tensorboard': {'use_tb': True,\n",
       "  'tb_logs_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/logs',\n",
       "  'get_tb_callback_fn_name': 'get_tb_callback_fn',\n",
       "  'tb_callback_parms': {'histogram_freq': 1, 'update_freq': 'batch'}},\n",
       " 'prediction_logging': {'use_prediction_logging': True,\n",
       "  'get_prediction_logging_fn_name': 'get_pred_logging_callback_fn'},\n",
       " 'model_checkpts': {'use_model_checkpts': True,\n",
       "  'model_checkpts_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/model-checkpts',\n",
       "  'get_model_checkpt_callback_fn_name': 'get_model_checkpt_callback_fn',\n",
       "  'model_checkpt_callback_parms': {'mode': 'max', 'save_best_only': True}},\n",
       " 'feedback': {'freeze_layers': False},\n",
       " 'random_seed': 20220523,\n",
       " 'freeze_layers': False,\n",
       " 'graph_location': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/graphs'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_experiment = False\n",
    "if \"discard_experiment\" in cfg:\n",
    "    discard_experiment = cfg[\"discard_experiment\"]\n",
    "cfg[\"timestamp\"] = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric constructor function: get_sparse_categorical_accuracy_fn\n"
     ]
    }
   ],
   "source": [
    "# specify a function that will construct the loss function\n",
    "get_loss_fn_name = cfg[\"loss\"][\"get_loss_fn_name\"]\n",
    "get_loss_fn = getattr(loss_constructors, get_loss_fn_name)\n",
    "# Construct the loss function\n",
    "loss_fn = get_loss_fn(cfg)\n",
    "\n",
    "the_metrics = []\n",
    "if cfg[\"metrics\"][\"use_metrics\"]:\n",
    "    get_metrics_fn_names = cfg[\"metrics\"][\"get_metrics_fn_names\"]\n",
    "    get_metrics_fn_parms = cfg[\"metrics\"][\"metrics_fn_parms\"]\n",
    "    assert len(get_metrics_fn_names) == len(get_metrics_fn_parms)\n",
    "    for get_mf_name, mf_parms in zip(get_metrics_fn_names, get_metrics_fn_parms):\n",
    "        get_metric_fn = getattr(metric_constructors, get_mf_name)\n",
    "        print(f\"Metric constructor function: {get_metric_fn.__name__}\")\n",
    "        metric_fn = get_metric_fn(mf_parms)\n",
    "        the_metrics.append(metric_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg[\"saved_model\"][\"use_saved_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: importing saved model /home/annazan/fAIr-utilities/ramp-code/ramp/checkpoint.tf\n",
      "-------\n",
      "-------[<keras.metrics.metrics.SparseCategoricalAccuracy object at 0x7f8b7a082c70>]\n",
      "-------\n",
      "-------[<keras.metrics.metrics.SparseCategoricalAccuracy object at 0x7f8b7a082c70>]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import Precision\n",
    "from pathlib import Path\n",
    "\n",
    "#### construct optimizer ####\n",
    "get_optimizer_fn_name = cfg[\"optimizer\"][\"get_optimizer_fn_name\"]\n",
    "get_optimizer_fn = getattr(optimizer_constructors, get_optimizer_fn_name)\n",
    "\n",
    "optimizer = get_optimizer_fn(cfg)\n",
    "\n",
    "the_model = None\n",
    "\n",
    "# SG: Using the saved model in this cell\n",
    "working_ramp_home = os.environ[\"RAMP_HOME\"]\n",
    "# load (construct) the model\n",
    "model_path = Path(working_ramp_home) / cfg[\"saved_model\"][\"saved_model_path\"]\n",
    "print(f\"Model: importing saved model {str(model_path)}\")\n",
    "the_model = tf.keras.models.load_model(model_path)\n",
    "assert (\n",
    "    the_model is not None\n",
    "), f\"the saved model was not constructed: {model_path}\"\n",
    "\n",
    "if cfg[\"freeze_layers\"]:\n",
    "    for layer in the_model.layers:\n",
    "        layer.trainable = False  # freeze previous layers only update new layers\n",
    "        # print(\"Setting previous model layers traininable : False\")\n",
    "\n",
    "\n",
    "print(\"-------\")\n",
    "print(f'-------{the_metrics}')\n",
    "print(\"-------\")\n",
    "\n",
    "# For class 0\n",
    "precision_class_0 = Precision(class_id=0)\n",
    "# For class 1\n",
    "precision_class_1 = Precision(class_id=1)\n",
    "metrics=[precision_class_0,precision_class_1]\n",
    "print(f'-------{the_metrics}')\n",
    "print(\"-------\")\n",
    "\n",
    "# If you don't want to save the original state of training, recompile the model.\n",
    "the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[the_metrics])\n",
    "# the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[precision_class_0,precision_class_1])\n",
    "\n",
    "# the_model.compile(optimizer = optimizer,\n",
    "#    loss=loss_fn,\n",
    "#    metrics = [get_iou_coef_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1), dtype=float32, numpy=\n",
       "array([[[2.9957325 ]],\n",
       "\n",
       "       [[0.22314365]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of loss fn with multiple prediction labels but only binary true labels\n",
    "y_true = [[[[0, 1]]]]\n",
    "y_pred = [[[[0.05, 0.95, 0, 0]]], [[[0.1, 0.8, 0.1, 0]]]]\n",
    "loss_fn(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1), dtype=float32, numpy=\n",
       "array([[[2.9957325 ]],\n",
       "\n",
       "       [[0.22314365]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cfg[\"freeze_layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg[\"saved_model\"][\"save_optimizer_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, None, None,   864         ['input_1[0][0]']                \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, None, None,   128         ['stem_conv[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, None, None,   0           ['stem_bn[0][0]']                \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, None, None,   288        ['stem_activation[0][0]']        \n",
      " D)                             32)                                                               \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, None, None,   128        ['block1a_dwconv[0][0]']         \n",
      " )                              32)                                                               \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, None, None,   0          ['block1a_bn[0][0]']             \n",
      " )                              32)                                                               \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, None, None,   0           ['block1a_activation[0][0]',     \n",
      "                                32)                               'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, None, None,   512         ['block1a_se_excite[0][0]']      \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, None, None,   64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      16)                                                               \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, None, None,   1536        ['block1a_project_bn[0][0]']     \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, None, None,   384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       96)                                                               \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, None, None,   0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       96)                                                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, None, None,   864        ['block2a_expand_activation[0][0]\n",
      " D)                             96)                              ']                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, None, None,   384        ['block2a_dwconv[0][0]']         \n",
      " )                              96)                                                               \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, None, None,   0          ['block2a_bn[0][0]']             \n",
      " )                              96)                                                               \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, None, None,   0           ['block2a_activation[0][0]',     \n",
      "                                96)                               'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, None, None,   2304        ['block2a_se_excite[0][0]']      \n",
      "                                24)                                                               \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, None, None,   96         ['block2a_project_conv[0][0]']   \n",
      " lization)                      24)                                                               \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, None, None,   3456        ['block2a_project_bn[0][0]']     \n",
      "                                144)                                                              \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, None, None,   576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                       144)                                                              \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, None, None,   0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                       144)                                                              \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, None, None,   1296       ['block2b_expand_activation[0][0]\n",
      " D)                             144)                             ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, None, None,   576        ['block2b_dwconv[0][0]']         \n",
      " )                              144)                                                              \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, None, None,   0          ['block2b_bn[0][0]']             \n",
      " )                              144)                                                              \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, None, None,   0           ['block2b_activation[0][0]',     \n",
      "                                144)                              'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, None, None,   3456        ['block2b_se_excite[0][0]']      \n",
      "                                24)                                                               \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, None, None,   96         ['block2b_project_conv[0][0]']   \n",
      " lization)                      24)                                                               \n",
      "                                                                                                  \n",
      " block2b_drop (FixedDropout)    (None, None, None,   0           ['block2b_project_bn[0][0]']     \n",
      "                                24)                                                               \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, None, None,   0           ['block2b_drop[0][0]',           \n",
      "                                24)                               'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, None, None,   3456        ['block2b_add[0][0]']            \n",
      "                                144)                                                              \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, None, None,   576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                       144)                                                              \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, None, None,   0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                       144)                                                              \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, None, None,   3600       ['block3a_expand_activation[0][0]\n",
      " D)                             144)                             ']                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, None, None,   576        ['block3a_dwconv[0][0]']         \n",
      " )                              144)                                                              \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, None, None,   0          ['block3a_bn[0][0]']             \n",
      " )                              144)                                                              \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, None, None,   0           ['block3a_activation[0][0]',     \n",
      "                                144)                              'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, None, None,   5760        ['block3a_se_excite[0][0]']      \n",
      "                                40)                                                               \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, None, None,   160        ['block3a_project_conv[0][0]']   \n",
      " lization)                      40)                                                               \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, None, None,   9600        ['block3a_project_bn[0][0]']     \n",
      "                                240)                                                              \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, None, None,   960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                       240)                                                              \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, None, None,   0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                       240)                                                              \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, None, None,   6000       ['block3b_expand_activation[0][0]\n",
      " D)                             240)                             ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, None, None,   960        ['block3b_dwconv[0][0]']         \n",
      " )                              240)                                                              \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, None, None,   0          ['block3b_bn[0][0]']             \n",
      " )                              240)                                                              \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, None, None,   0           ['block3b_activation[0][0]',     \n",
      "                                240)                              'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, None, None,   9600        ['block3b_se_excite[0][0]']      \n",
      "                                40)                                                               \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, None, None,   160        ['block3b_project_conv[0][0]']   \n",
      " lization)                      40)                                                               \n",
      "                                                                                                  \n",
      " block3b_drop (FixedDropout)    (None, None, None,   0           ['block3b_project_bn[0][0]']     \n",
      "                                40)                                                               \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, None, None,   0           ['block3b_drop[0][0]',           \n",
      "                                40)                               'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, None, None,   9600        ['block3b_add[0][0]']            \n",
      "                                240)                                                              \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, None, None,   960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                       240)                                                              \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, None, None,   0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                       240)                                                              \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, None, None,   2160       ['block4a_expand_activation[0][0]\n",
      " D)                             240)                             ']                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, None, None,   960        ['block4a_dwconv[0][0]']         \n",
      " )                              240)                                                              \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, None, None,   0          ['block4a_bn[0][0]']             \n",
      " )                              240)                                                              \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, None, None,   0           ['block4a_activation[0][0]',     \n",
      "                                240)                              'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, None, None,   19200       ['block4a_se_excite[0][0]']      \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, None, None,   320        ['block4a_project_conv[0][0]']   \n",
      " lization)                      80)                                                               \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, None, None,   38400       ['block4a_project_bn[0][0]']     \n",
      "                                480)                                                              \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, None, None,   1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                       480)                                                              \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, None, None,   0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                       480)                                                              \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4b_expand_activation[0][0]\n",
      " D)                             480)                             ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, None, None,   1920       ['block4b_dwconv[0][0]']         \n",
      " )                              480)                                                              \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, None, None,   0          ['block4b_bn[0][0]']             \n",
      " )                              480)                                                              \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, None, None,   0           ['block4b_activation[0][0]',     \n",
      "                                480)                              'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, None, None,   38400       ['block4b_se_excite[0][0]']      \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, None, None,   320        ['block4b_project_conv[0][0]']   \n",
      " lization)                      80)                                                               \n",
      "                                                                                                  \n",
      " block4b_drop (FixedDropout)    (None, None, None,   0           ['block4b_project_bn[0][0]']     \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, None, None,   0           ['block4b_drop[0][0]',           \n",
      "                                80)                               'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, None, None,   38400       ['block4b_add[0][0]']            \n",
      "                                480)                                                              \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, None, None,   1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                       480)                                                              \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, None, None,   0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                       480)                                                              \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4c_expand_activation[0][0]\n",
      " D)                             480)                             ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, None, None,   1920       ['block4c_dwconv[0][0]']         \n",
      " )                              480)                                                              \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, None, None,   0          ['block4c_bn[0][0]']             \n",
      " )                              480)                                                              \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, None, None,   0           ['block4c_activation[0][0]',     \n",
      "                                480)                              'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, None, None,   38400       ['block4c_se_excite[0][0]']      \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, None, None,   320        ['block4c_project_conv[0][0]']   \n",
      " lization)                      80)                                                               \n",
      "                                                                                                  \n",
      " block4c_drop (FixedDropout)    (None, None, None,   0           ['block4c_project_bn[0][0]']     \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, None, None,   0           ['block4c_drop[0][0]',           \n",
      "                                80)                               'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, None, None,   38400       ['block4c_add[0][0]']            \n",
      "                                480)                                                              \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, None, None,   1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                       480)                                                              \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, None, None,   0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                       480)                                                              \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, None, None,   12000      ['block5a_expand_activation[0][0]\n",
      " D)                             480)                             ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, None, None,   1920       ['block5a_dwconv[0][0]']         \n",
      " )                              480)                                                              \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, None, None,   0          ['block5a_bn[0][0]']             \n",
      " )                              480)                                                              \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, None, None,   0           ['block5a_activation[0][0]',     \n",
      "                                480)                              'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, None, None,   53760       ['block5a_se_excite[0][0]']      \n",
      "                                112)                                                              \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, None, None,   448        ['block5a_project_conv[0][0]']   \n",
      " lization)                      112)                                                              \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, None, None,   75264       ['block5a_project_bn[0][0]']     \n",
      "                                672)                                                              \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, None, None,   2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                       672)                                                              \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, None, None,   0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                       672)                                                              \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5b_expand_activation[0][0]\n",
      " D)                             672)                             ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, None, None,   2688       ['block5b_dwconv[0][0]']         \n",
      " )                              672)                                                              \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, None, None,   0          ['block5b_bn[0][0]']             \n",
      " )                              672)                                                              \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, None, None,   0           ['block5b_activation[0][0]',     \n",
      "                                672)                              'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, None, None,   75264       ['block5b_se_excite[0][0]']      \n",
      "                                112)                                                              \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, None, None,   448        ['block5b_project_conv[0][0]']   \n",
      " lization)                      112)                                                              \n",
      "                                                                                                  \n",
      " block5b_drop (FixedDropout)    (None, None, None,   0           ['block5b_project_bn[0][0]']     \n",
      "                                112)                                                              \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, None, None,   0           ['block5b_drop[0][0]',           \n",
      "                                112)                              'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, None, None,   75264       ['block5b_add[0][0]']            \n",
      "                                672)                                                              \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, None, None,   2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                       672)                                                              \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, None, None,   0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                       672)                                                              \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5c_expand_activation[0][0]\n",
      " D)                             672)                             ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, None, None,   2688       ['block5c_dwconv[0][0]']         \n",
      " )                              672)                                                              \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, None, None,   0          ['block5c_bn[0][0]']             \n",
      " )                              672)                                                              \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, None, None,   0           ['block5c_activation[0][0]',     \n",
      "                                672)                              'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, None, None,   75264       ['block5c_se_excite[0][0]']      \n",
      "                                112)                                                              \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, None, None,   448        ['block5c_project_conv[0][0]']   \n",
      " lization)                      112)                                                              \n",
      "                                                                                                  \n",
      " block5c_drop (FixedDropout)    (None, None, None,   0           ['block5c_project_bn[0][0]']     \n",
      "                                112)                                                              \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, None, None,   0           ['block5c_drop[0][0]',           \n",
      "                                112)                              'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, None, None,   75264       ['block5c_add[0][0]']            \n",
      "                                672)                                                              \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, None, None,   2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                       672)                                                              \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, None, None,   0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                       672)                                                              \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block6a_expand_activation[0][0]\n",
      " D)                             672)                             ']                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, None, None,   2688       ['block6a_dwconv[0][0]']         \n",
      " )                              672)                                                              \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, None, None,   0          ['block6a_bn[0][0]']             \n",
      " )                              672)                                                              \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, None, None,   0           ['block6a_activation[0][0]',     \n",
      "                                672)                              'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, None, None,   129024      ['block6a_se_excite[0][0]']      \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, None, None,   768        ['block6a_project_conv[0][0]']   \n",
      " lization)                      192)                                                              \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, None, None,   221184      ['block6a_project_bn[0][0]']     \n",
      "                                1152)                                                             \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, None, None,   4608       ['block6b_expand_conv[0][0]']    \n",
      " ization)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, None, None,   0          ['block6b_expand_bn[0][0]']      \n",
      " ivation)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6b_expand_activation[0][0]\n",
      " D)                             1152)                            ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, None, None,   4608       ['block6b_dwconv[0][0]']         \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, None, None,   0          ['block6b_bn[0][0]']             \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, None, None,   0           ['block6b_activation[0][0]',     \n",
      "                                1152)                             'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, None, None,   221184      ['block6b_se_excite[0][0]']      \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, None, None,   768        ['block6b_project_conv[0][0]']   \n",
      " lization)                      192)                                                              \n",
      "                                                                                                  \n",
      " block6b_drop (FixedDropout)    (None, None, None,   0           ['block6b_project_bn[0][0]']     \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, None, None,   0           ['block6b_drop[0][0]',           \n",
      "                                192)                              'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, None, None,   221184      ['block6b_add[0][0]']            \n",
      "                                1152)                                                             \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, None, None,   4608       ['block6c_expand_conv[0][0]']    \n",
      " ization)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, None, None,   0          ['block6c_expand_bn[0][0]']      \n",
      " ivation)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6c_expand_activation[0][0]\n",
      " D)                             1152)                            ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, None, None,   4608       ['block6c_dwconv[0][0]']         \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, None, None,   0          ['block6c_bn[0][0]']             \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, None, None,   0           ['block6c_activation[0][0]',     \n",
      "                                1152)                             'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, None, None,   221184      ['block6c_se_excite[0][0]']      \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, None, None,   768        ['block6c_project_conv[0][0]']   \n",
      " lization)                      192)                                                              \n",
      "                                                                                                  \n",
      " block6c_drop (FixedDropout)    (None, None, None,   0           ['block6c_project_bn[0][0]']     \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, None, None,   0           ['block6c_drop[0][0]',           \n",
      "                                192)                              'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, None, None,   221184      ['block6c_add[0][0]']            \n",
      "                                1152)                                                             \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, None, None,   4608       ['block6d_expand_conv[0][0]']    \n",
      " ization)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, None, None,   0          ['block6d_expand_bn[0][0]']      \n",
      " ivation)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6d_expand_activation[0][0]\n",
      " D)                             1152)                            ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, None, None,   4608       ['block6d_dwconv[0][0]']         \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, None, None,   0          ['block6d_bn[0][0]']             \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, None, None,   0           ['block6d_activation[0][0]',     \n",
      "                                1152)                             'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, None, None,   221184      ['block6d_se_excite[0][0]']      \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, None, None,   768        ['block6d_project_conv[0][0]']   \n",
      " lization)                      192)                                                              \n",
      "                                                                                                  \n",
      " block6d_drop (FixedDropout)    (None, None, None,   0           ['block6d_project_bn[0][0]']     \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, None, None,   0           ['block6d_drop[0][0]',           \n",
      "                                192)                              'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, None, None,   221184      ['block6d_add[0][0]']            \n",
      "                                1152)                                                             \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, None, None,   4608       ['block7a_expand_conv[0][0]']    \n",
      " ization)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, None, None,   0          ['block7a_expand_bn[0][0]']      \n",
      " ivation)                       1152)                                                             \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, None, None,   10368      ['block7a_expand_activation[0][0]\n",
      " D)                             1152)                            ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, None, None,   4608       ['block7a_dwconv[0][0]']         \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, None, None,   0          ['block7a_bn[0][0]']             \n",
      " )                              1152)                                                             \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, None, None,   0           ['block7a_activation[0][0]',     \n",
      "                                1152)                             'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, None, None,   368640      ['block7a_se_excite[0][0]']      \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, None, None,   1280       ['block7a_project_conv[0][0]']   \n",
      " lization)                      320)                                                              \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, None, None,   409600      ['block7a_project_bn[0][0]']     \n",
      "                                1280)                                                             \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, None, None,   5120        ['top_conv[0][0]']               \n",
      "                                1280)                                                             \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, None, None,   0           ['top_bn[0][0]']                 \n",
      "                                1280)                                                             \n",
      "                                                                                                  \n",
      " decoder_stage0_upsampling (UpS  (None, None, None,   0          ['top_activation[0][0]']         \n",
      " ampling2D)                     1280)                                                             \n",
      "                                                                                                  \n",
      " decoder_stage0_concat (Concate  (None, None, None,   0          ['decoder_stage0_upsampling[0][0]\n",
      " nate)                          1952)                            ',                               \n",
      "                                                                  'block6a_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " decoder_stage0a_conv (Conv2D)  (None, None, None,   4497408     ['decoder_stage0_concat[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0a_bn (BatchNorma  (None, None, None,   1024       ['decoder_stage0a_conv[0][0]']   \n",
      " lization)                      256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0a_relu (Activati  (None, None, None,   0          ['decoder_stage0a_bn[0][0]']     \n",
      " on)                            256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_conv (Conv2D)  (None, None, None,   589824      ['decoder_stage0a_relu[0][0]']   \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_bn (BatchNorma  (None, None, None,   1024       ['decoder_stage0b_conv[0][0]']   \n",
      " lization)                      256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_relu (Activati  (None, None, None,   0          ['decoder_stage0b_bn[0][0]']     \n",
      " on)                            256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_upsampling (UpS  (None, None, None,   0          ['decoder_stage0b_relu[0][0]']   \n",
      " ampling2D)                     256)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_concat (Concate  (None, None, None,   0          ['decoder_stage1_upsampling[0][0]\n",
      " nate)                          496)                             ',                               \n",
      "                                                                  'block4a_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " decoder_stage1a_conv (Conv2D)  (None, None, None,   571392      ['decoder_stage1_concat[0][0]']  \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1a_bn (BatchNorma  (None, None, None,   512        ['decoder_stage1a_conv[0][0]']   \n",
      " lization)                      128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1a_relu (Activati  (None, None, None,   0          ['decoder_stage1a_bn[0][0]']     \n",
      " on)                            128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_conv (Conv2D)  (None, None, None,   147456      ['decoder_stage1a_relu[0][0]']   \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_bn (BatchNorma  (None, None, None,   512        ['decoder_stage1b_conv[0][0]']   \n",
      " lization)                      128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_relu (Activati  (None, None, None,   0          ['decoder_stage1b_bn[0][0]']     \n",
      " on)                            128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_upsampling (UpS  (None, None, None,   0          ['decoder_stage1b_relu[0][0]']   \n",
      " ampling2D)                     128)                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_concat (Concate  (None, None, None,   0          ['decoder_stage2_upsampling[0][0]\n",
      " nate)                          272)                             ',                               \n",
      "                                                                  'block3a_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " decoder_stage2a_conv (Conv2D)  (None, None, None,   156672      ['decoder_stage2_concat[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage2a_bn (BatchNorma  (None, None, None,   256        ['decoder_stage2a_conv[0][0]']   \n",
      " lization)                      64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage2a_relu (Activati  (None, None, None,   0          ['decoder_stage2a_bn[0][0]']     \n",
      " on)                            64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage2b_conv (Conv2D)  (None, None, None,   36864       ['decoder_stage2a_relu[0][0]']   \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage2b_bn (BatchNorma  (None, None, None,   256        ['decoder_stage2b_conv[0][0]']   \n",
      " lization)                      64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage2b_relu (Activati  (None, None, None,   0          ['decoder_stage2b_bn[0][0]']     \n",
      " on)                            64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3_upsampling (UpS  (None, None, None,   0          ['decoder_stage2b_relu[0][0]']   \n",
      " ampling2D)                     64)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3_concat (Concate  (None, None, None,   0          ['decoder_stage3_upsampling[0][0]\n",
      " nate)                          160)                             ',                               \n",
      "                                                                  'block2a_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " decoder_stage3a_conv (Conv2D)  (None, None, None,   46080       ['decoder_stage3_concat[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3a_bn (BatchNorma  (None, None, None,   128        ['decoder_stage3a_conv[0][0]']   \n",
      " lization)                      32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3a_relu (Activati  (None, None, None,   0          ['decoder_stage3a_bn[0][0]']     \n",
      " on)                            32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3b_conv (Conv2D)  (None, None, None,   9216        ['decoder_stage3a_relu[0][0]']   \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3b_bn (BatchNorma  (None, None, None,   128        ['decoder_stage3b_conv[0][0]']   \n",
      " lization)                      32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage3b_relu (Activati  (None, None, None,   0          ['decoder_stage3b_bn[0][0]']     \n",
      " on)                            32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage4_upsampling (UpS  (None, None, None,   0          ['decoder_stage3b_relu[0][0]']   \n",
      " ampling2D)                     32)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_conv (Conv2D)  (None, None, None,   4608        ['decoder_stage4_upsampling[0][0]\n",
      "                                16)                              ']                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_bn (BatchNorma  (None, None, None,   64         ['decoder_stage4a_conv[0][0]']   \n",
      " lization)                      16)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_relu (Activati  (None, None, None,   0          ['decoder_stage4a_bn[0][0]']     \n",
      " on)                            16)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage4b_conv (Conv2D)  (None, None, None,   2304        ['decoder_stage4a_relu[0][0]']   \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage4b_bn (BatchNorma  (None, None, None,   64         ['decoder_stage4b_conv[0][0]']   \n",
      " lization)                      16)                                                               \n",
      "                                                                                                  \n",
      " decoder_stage4b_relu (Activati  (None, None, None,   0          ['decoder_stage4b_bn[0][0]']     \n",
      " on)                            16)                                                               \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, None, None,   580         ['decoder_stage4b_relu[0][0]']   \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, None, None,   0           ['final_conv[0][0]']             \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,115,936\n",
      "Trainable params: 0\n",
      "Non-trainable params: 10,115,936\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(the_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "* train img dir/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/chips\n",
      "* train mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/binarymasks\n",
      "* input img shape[256, 256]\n",
      "* output img shape[256, 256]\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "from ramp.training.augmentation_constructors import get_augmentation_fn\n",
    "from ramp.utils.misc_ramp_utils import get_num_files\n",
    "from ramp.data_mgmt.data_generator import (\n",
    "    test_batches_from_gtiff_dirs,\n",
    "    training_batches_from_gtiff_dirs,\n",
    ")\n",
    "#### define data directories ####\n",
    "train_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_img_dir\"]\n",
    "train_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_mask_dir\"]\n",
    "val_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_img_dir\"]\n",
    "val_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_mask_dir\"]\n",
    "\n",
    "#### get the augmentation transform ####\n",
    "# aug = None\n",
    "if cfg[\"augmentation\"][\"use_aug\"]:\n",
    "    aug = get_augmentation_fn(cfg)\n",
    "\n",
    "## RUNTIME Parameters\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "input_img_shape = cfg[\"input_img_shape\"]\n",
    "output_img_shape = cfg[\"output_img_shape\"]\n",
    "\n",
    "n_training = get_num_files(train_img_dir, \"*.tif\")\n",
    "n_val = get_num_files(val_img_dir, \"*.tif\")\n",
    "steps_per_epoch = n_training // batch_size\n",
    "validation_steps = n_val // batch_size\n",
    "# Testing step , not recommended\n",
    "if validation_steps <= 0:\n",
    "    validation_steps = 1\n",
    "\n",
    "# add these back to the config\n",
    "# in case they are needed by callbacks\n",
    "cfg[\"runtime\"] = {}\n",
    "cfg[\"runtime\"][\"n_training\"] = n_training\n",
    "cfg[\"runtime\"][\"n_val\"] = n_val\n",
    "cfg[\"runtime\"][\"steps_per_epoch\"] = steps_per_epoch\n",
    "cfg[\"runtime\"][\"validation_steps\"] = validation_steps\n",
    "\n",
    "train_batches = None\n",
    "\n",
    "if aug is not None:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir,\n",
    "        train_mask_dir,\n",
    "        batch_size,\n",
    "        input_img_shape,\n",
    "        output_img_shape,\n",
    "        transforms=aug,\n",
    "    )\n",
    "else:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir, train_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "    )\n",
    "assert train_batches is not None, \"training batches were not constructed\"\n",
    "print(f\"-------\\n* train img dir{train_img_dir}\\n* train mask dir{train_mask_dir}\")\n",
    "print(f\"* input img shape{input_img_shape}\\n* output img shape{output_img_shape}\")\n",
    "\n",
    "print(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Batches are a tf.data.Dataset type\n",
    "print(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single batch as numpy to explore\n",
    "iter = tf.data.Dataset.as_numpy_iterator(train_batches)\n",
    "(X_batch, y_true_batch) = iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is: 2\n",
      "Example X entry: [0. 0. 0.]\n",
      "Input data shape (X): (2, 256, 256, 3)\n",
      "Ground truth data shape (y_true): (2, 256, 256, 1)\n",
      "Example y_true:  [0]\n",
      "The unique labels in the y_true: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Print useful info\n",
    "print(\"Batch size is:\", X_batch.shape[0])\n",
    "# Appears to be floats between 0 and 1\n",
    "print(\"Example X entry:\", X_batch[0, 0, 0, :])\n",
    "print(\"Input data shape (X):\", X_batch.shape)\n",
    "print(\"Ground truth data shape (y_true):\", y_true_batch.shape)\n",
    "print(\"Example y_true: \", y_true_batch[1, 0, 0, :])\n",
    "print(f\"The unique labels in the y_true: {np.unique(y_true_batch[0, :, :, 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Get some predictions from the model for the batch\n",
    "y_pred_batch = the_model.predict(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions y_pred_batch are: (2, 256, 256, 4)\n"
     ]
    }
   ],
   "source": [
    "# Shape of output predictions\n",
    "print(\"Predictions y_pred_batch are:\", y_pred_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9283397e-01 3.8708819e-04 6.6278717e-03 1.5105018e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example single pixel prediction\n",
    "single_prediction = y_pred_batch[0, 0, 0, :]\n",
    "print(single_prediction)\n",
    "\n",
    "# Single prediction sums to 1: probabilties over the four categories of the model\n",
    "single_prediction.sum().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 256, 256), dtype=float32, numpy=\n",
       "array([[[0.00719184, 0.00163743, 0.00078314, ..., 0.00273354,\n",
       "         0.00382917, 0.01771392],\n",
       "        [0.00257339, 0.00035113, 0.0001875 , ..., 0.0018671 ,\n",
       "         0.00171824, 0.00425469],\n",
       "        [0.0013764 , 0.00016843, 0.00013517, ..., 0.00075824,\n",
       "         0.00099681, 0.00275387],\n",
       "        ...,\n",
       "        [0.00275304, 0.00040916, 0.00045718, ..., 0.00119245,\n",
       "         0.00132152, 0.00308526],\n",
       "        [0.00654305, 0.00064328, 0.00049603, ..., 0.00096906,\n",
       "         0.00073251, 0.00196883],\n",
       "        [0.01925141, 0.00276636, 0.0024634 , ..., 0.00283804,\n",
       "         0.00418869, 0.01054761]],\n",
       "\n",
       "       [[0.00770679, 0.00183438, 0.00089808, ..., 0.00540379,\n",
       "         0.00736356, 0.02895815],\n",
       "        [0.00280761, 0.00040809, 0.0002254 , ..., 0.00480509,\n",
       "         0.00484222, 0.00905124],\n",
       "        [0.00153257, 0.00020359, 0.00017749, ..., 0.00257886,\n",
       "         0.00311687, 0.00616684],\n",
       "        ...,\n",
       "        [0.00483973, 0.00105516, 0.00147329, ..., 0.00148805,\n",
       "         0.00172526, 0.00374711],\n",
       "        [0.0107092 , 0.00144901, 0.00123734, ..., 0.00117829,\n",
       "         0.00092511, 0.00227371],\n",
       "        [0.02548383, 0.00442716, 0.00422359, ..., 0.00319174,\n",
       "         0.00473663, 0.01153078]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.loss(y_true_batch, y_pred_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "* val img dir/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/val-chips\n",
      "* val mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/val-binarymasks\n",
      "-------\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.uint8, name=None))>\n",
      "*\n",
      "*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation batches\n",
    "val_batches = test_batches_from_gtiff_dirs(\n",
    "    val_img_dir, val_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    ")\n",
    "\n",
    "assert val_batches is not None, \"validation batches were not constructed\"\n",
    "print(f\"-------\\n* val img dir{val_img_dir}\\n* val mask dir{val_mask_dir}\\n-------\")\n",
    "print(val_batches)\n",
    "print('*\\n*\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "# ---------------\n",
    "## Callbacks ##\n",
    "callbacks_list = []\n",
    "\n",
    "if not discard_experiment:\n",
    "    # get model checkpoint callback\n",
    "    if cfg[\"model_checkpts\"][\"use_model_checkpts\"]:\n",
    "        get_model_checkpt_callback_fn_name = cfg[\"model_checkpts\"][\n",
    "            \"get_model_checkpt_callback_fn_name\"\n",
    "        ]\n",
    "        get_model_checkpt_callback_fn = getattr(\n",
    "            callback_constructors, get_model_checkpt_callback_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_model_checkpt_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard callback\n",
    "    if cfg[\"tensorboard\"][\"use_tb\"]:\n",
    "        get_tb_callback_fn_name = cfg[\"tensorboard\"][\"get_tb_callback_fn_name\"]\n",
    "        get_tb_callback_fn = getattr(callback_constructors, get_tb_callback_fn_name)\n",
    "        callbacks_list.append(get_tb_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard model prediction logging callback\n",
    "    if cfg[\"prediction_logging\"][\"use_prediction_logging\"]:\n",
    "        assert cfg[\"tensorboard\"][\n",
    "            \"use_tb\"\n",
    "        ], \"Tensorboard logging must be turned on to enable prediction logging\"\n",
    "        get_prediction_logging_fn_name = cfg[\"prediction_logging\"][\n",
    "            \"get_prediction_logging_fn_name\"\n",
    "        ]\n",
    "        get_prediction_logging_fn = getattr(\n",
    "            callback_constructors, get_prediction_logging_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_prediction_logging_fn(the_model, cfg))\n",
    "\n",
    "# free up RAM\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "if cfg[\"early_stopping\"][\"use_early_stopping\"]:\n",
    "    callbacks_list.append(callback_constructors.get_early_stopping_callback_fn(cfg))\n",
    "\n",
    "    # get cyclic learning scheduler callback\n",
    "if cfg[\"cyclic_learning_scheduler\"][\"use_clr\"]:\n",
    "    assert not cfg[\"early_stopping\"][\n",
    "        \"use_early_stopping\"\n",
    "    ], \"cannot use early_stopping with cycling_learning_scheduler\"\n",
    "    get_clr_callback_fn_name = cfg[\"cyclic_learning_scheduler\"][\n",
    "        \"get_clr_callback_fn_name\"\n",
    "    ]\n",
    "    get_clr_callback_fn = getattr(callback_constructors, get_clr_callback_fn_name)\n",
    "    callbacks_list.append(get_clr_callback_fn(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with 10 epochs , 2 batch size , 4 steps per epoch , 1 validation steps......\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/stepss: 0.4252 - sparse_categorical_accuracy: 0.87\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.3854 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 26ms/stepss: 0.3195 - sparse_categorical_accuracy: 0.88\n",
      "4/4 [==============================] - 2s 726ms/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9077 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 26ms/stepss: 0.2175 - sparse_categorical_accuracy: 0.95\n",
      "4/4 [==============================] - 2s 723ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 25ms/stepss: 0.1447 - sparse_categorical_accuracy: 0.95\n",
      "4/4 [==============================] - 2s 724ms/step - loss: 0.1447 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 27ms/stepss: 0.2133 - sparse_categorical_accuracy: 0.93\n",
      "4/4 [==============================] - 2s 725ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9330 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 25ms/stepss: 0.1909 - sparse_categorical_accuracy: 0.93\n",
      "4/4 [==============================] - 2s 726ms/step - loss: 0.1909 - sparse_categorical_accuracy: 0.9311 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 25ms/stepss: 0.1578 - sparse_categorical_accuracy: 0.96\n",
      "4/4 [==============================] - 2s 756ms/step - loss: 0.1578 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 25ms/stepss: 0.2696 - sparse_categorical_accuracy: 0.92\n",
      "4/4 [==============================] - 2s 725ms/step - loss: 0.2696 - sparse_categorical_accuracy: 0.9214 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 25ms/stepss: 0.1384 - sparse_categorical_accuracy: 0.94\n",
      "4/4 [==============================] - 2s 723ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 24ms/stepss: 0.1036 - sparse_categorical_accuracy: 0.97\n",
      "4/4 [==============================] - 2s 728ms/step - loss: 0.1782 - sparse_categorical_accuracy: 0.9621 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9050\n",
      "Training Finished , Time taken to train : 41.03265338199708 seconds\n",
      "\n",
      "-----\n",
      "History:\n",
      "dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy'])\n",
      "\n",
      "-----\n",
      "Generating graphs ....\n",
      "Graph generated at : /home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/graphs\n",
      "accuracy [0.8881473541259766, 0.9076973795890808, 0.9520198106765747, 0.9520699381828308, 0.9329550862312317, 0.9311008453369141, 0.9622693657875061, 0.9213954210281372, 0.9487696886062622, 0.9621451497077942]\n",
      "accuracy [0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125, 0.9049835205078125]\n",
      "loss [0.3854493200778961, 0.25861790776252747, 0.21751797199249268, 0.14468169212341309, 0.21325278282165527, 0.19087547063827515, 0.15778405964374542, 0.2696223556995392, 0.13840332627296448, 0.17815907299518585]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "\n",
    "## Main training block ##\n",
    "n_epochs = cfg[\"num_epochs\"]\n",
    "# SG: manually make this 10\n",
    "n_epochs = 10\n",
    "print(\n",
    "    f\"Starting Training with {n_epochs} epochs , {batch_size} batch size , {steps_per_epoch} steps per epoch , {validation_steps} validation steps......\"\n",
    ")\n",
    "if validation_steps <= 0:\n",
    "    raise RaiseError(\n",
    "        \"Not enough data for training, Increase image or Try reducing batchsize/epochs\"\n",
    "    )\n",
    "# FIXME : Make checkpoint\n",
    "start = perf_counter()\n",
    "history = the_model.fit(\n",
    "    train_batches,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_batches,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list,\n",
    ")\n",
    "end = perf_counter()\n",
    "print(f\"Training Finished , Time taken to train : {end-start} seconds\")\n",
    "print('\\n-----\\nHistory:')\n",
    "print(history.history.keys())\n",
    "print('\\n-----')\n",
    "\n",
    "# plot the training and validation accuracy and loss at each epoch\n",
    "print(\"Generating graphs ....\")\n",
    "if not os.path.exists(cfg[\"graph_location\"]):\n",
    "    os.mkdir(cfg[\"graph_location\"])\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    f\"{cfg['graph_location']}/training_validation_sparse_categorical_accuracy.png\"\n",
    ")\n",
    "print(f\"Graph generated at : {cfg['graph_location']}\")\n",
    "print(f\"accuracy {acc}\")\n",
    "print(f\"accuracy {val_acc}\")\n",
    "print(f\"loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPENDIX: from copying across\n",
    "\n",
    "#### construct optimizer ####\n",
    "get_optimizer_fn_name = cfg[\"optimizer\"][\"get_optimizer_fn_name\"]\n",
    "get_optimizer_fn = getattr(optimizer_constructors, get_optimizer_fn_name)\n",
    "\n",
    "optimizer = get_optimizer_fn(cfg)\n",
    "\n",
    "the_model = None\n",
    "\n",
    "if cfg[\"saved_model\"][\"use_saved_model\"]:\n",
    "    # load (construct) the model\n",
    "    model_path = Path(working_ramp_home) / cfg[\"saved_model\"][\"saved_model_path\"]\n",
    "    print(f\"Model: importing saved model {str(model_path)}\")\n",
    "    the_model = tf.keras.models.load_model(model_path)\n",
    "    assert (\n",
    "        the_model is not None\n",
    "    ), f\"the saved model was not constructed: {model_path}\"\n",
    "\n",
    "    if cfg[\"freeze_layers\"]:\n",
    "        for layer in the_model.layers:\n",
    "            layer.trainable = False  # freeze previous layers only update new layers\n",
    "            # print(\"Setting previous model layers traininable : False\")\n",
    "\n",
    "    if not cfg[\"saved_model\"][\"save_optimizer_state\"]:\n",
    "        print(\"-------\")\n",
    "        print(f'-------{the_metrics}')\n",
    "        print(\"-------\")\n",
    "        \n",
    "        # For class 0\n",
    "        precision_class_0 = Precision(class_id=0)\n",
    "        # For class 1\n",
    "        precision_class_1 = Precision(class_id=1)\n",
    "        metrics=[precision_class_0,precision_class_1]\n",
    "        print(f'-------{the_metrics}')\n",
    "        print(\"-------\")\n",
    "        \n",
    "        # If you don't want to save the original state of training, recompile the model.\n",
    "        the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[the_metrics])\n",
    "        # the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[precision_class_0,precision_class_1])\n",
    "        \n",
    "        # the_model.compile(optimizer = optimizer,\n",
    "        #    loss=loss_fn,\n",
    "        #    metrics = [get_iou_coef_fn])\n",
    "\n",
    "if not cfg[\"saved_model\"][\"use_saved_model\"]:\n",
    "    get_model_fn_name = cfg[\"model\"][\"get_model_fn_name\"]\n",
    "    get_model_fn = getattr(model_constructors, get_model_fn_name)\n",
    "    the_model = get_model_fn(cfg)\n",
    "\n",
    "    assert the_model is not None, f\"the model was not constructed: {model_path}\"\n",
    "    the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=the_metrics)\n",
    "\n",
    "print(the_model)\n",
    "cfg[\"datasets\"]\n",
    "\n",
    "#### define data directories ####\n",
    "train_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_img_dir\"]\n",
    "train_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_mask_dir\"]\n",
    "val_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_img_dir\"]\n",
    "val_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_mask_dir\"]\n",
    "\n",
    "#### get the augmentation transform ####\n",
    "# aug = None\n",
    "if cfg[\"augmentation\"][\"use_aug\"]:\n",
    "    aug = get_augmentation_fn(cfg)\n",
    "\n",
    "## RUNTIME Parameters\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "input_img_shape = cfg[\"input_img_shape\"]\n",
    "output_img_shape = cfg[\"output_img_shape\"]\n",
    "\n",
    "n_training = get_num_files(train_img_dir, \"*.tif\")\n",
    "n_val = get_num_files(val_img_dir, \"*.tif\")\n",
    "steps_per_epoch = n_training // batch_size\n",
    "validation_steps = n_val // batch_size\n",
    "# Testing step , not recommended\n",
    "if validation_steps <= 0:\n",
    "    validation_steps = 1\n",
    "\n",
    "# add these back to the config\n",
    "# in case they are needed by callbacks\n",
    "cfg[\"runtime\"] = {}\n",
    "cfg[\"runtime\"][\"n_training\"] = n_training\n",
    "cfg[\"runtime\"][\"n_val\"] = n_val\n",
    "cfg[\"runtime\"][\"steps_per_epoch\"] = steps_per_epoch\n",
    "cfg[\"runtime\"][\"validation_steps\"] = validation_steps\n",
    "\n",
    "train_batches = None\n",
    "\n",
    "if aug is not None:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir,\n",
    "        train_mask_dir,\n",
    "        batch_size,\n",
    "        input_img_shape,\n",
    "        output_img_shape,\n",
    "        transforms=aug,\n",
    "    )\n",
    "else:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir, train_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "    )\n",
    "\n",
    "assert train_batches is not None, \"training batches were not constructed\"\n",
    "print(f\"-------\\n* train img dir{train_img_dir}\\n* train mask dir{train_mask_dir}\")\n",
    "print(f\"* input img shape{input_img_shape}\\n* output img shape{output_img_shape}\")\n",
    "\n",
    "print(train_batches)\n",
    "\n",
    "val_batches = test_batches_from_gtiff_dirs(\n",
    "    val_img_dir, val_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    ")\n",
    "\n",
    "assert val_batches is not None, \"validation batches were not constructed\"\n",
    "print(f\"-------\\n* val img dir{val_img_dir}\\n* val mask dir{val_mask_dir}\\n-------\")\n",
    "print(val_batches)\n",
    "print('*\\n*\\n')\n",
    "\n",
    "## Callbacks ##\n",
    "callbacks_list = []\n",
    "\n",
    "if not discard_experiment:\n",
    "    # get model checkpoint callback\n",
    "    if cfg[\"model_checkpts\"][\"use_model_checkpts\"]:\n",
    "        get_model_checkpt_callback_fn_name = cfg[\"model_checkpts\"][\n",
    "            \"get_model_checkpt_callback_fn_name\"\n",
    "        ]\n",
    "        get_model_checkpt_callback_fn = getattr(\n",
    "            callback_constructors, get_model_checkpt_callback_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_model_checkpt_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard callback\n",
    "    if cfg[\"tensorboard\"][\"use_tb\"]:\n",
    "        get_tb_callback_fn_name = cfg[\"tensorboard\"][\"get_tb_callback_fn_name\"]\n",
    "        get_tb_callback_fn = getattr(callback_constructors, get_tb_callback_fn_name)\n",
    "        callbacks_list.append(get_tb_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard model prediction logging callback\n",
    "    if cfg[\"prediction_logging\"][\"use_prediction_logging\"]:\n",
    "        assert cfg[\"tensorboard\"][\n",
    "            \"use_tb\"\n",
    "        ], \"Tensorboard logging must be turned on to enable prediction logging\"\n",
    "        get_prediction_logging_fn_name = cfg[\"prediction_logging\"][\n",
    "            \"get_prediction_logging_fn_name\"\n",
    "        ]\n",
    "        get_prediction_logging_fn = getattr(\n",
    "            callback_constructors, get_prediction_logging_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_prediction_logging_fn(the_model, cfg))\n",
    "\n",
    "# free up RAM\n",
    "keras.backend.clear_session()\n",
    "\n",
    "if cfg[\"early_stopping\"][\"use_early_stopping\"]:\n",
    "    callbacks_list.append(callback_constructors.get_early_stopping_callback_fn(cfg))\n",
    "\n",
    "    # get cyclic learning scheduler callback\n",
    "if cfg[\"cyclic_learning_scheduler\"][\"use_clr\"]:\n",
    "    assert not cfg[\"early_stopping\"][\n",
    "        \"use_early_stopping\"\n",
    "    ], \"cannot use early_stopping with cycling_learning_scheduler\"\n",
    "    get_clr_callback_fn_name = cfg[\"cyclic_learning_scheduler\"][\n",
    "        \"get_clr_callback_fn_name\"\n",
    "    ]\n",
    "    get_clr_callback_fn = getattr(callback_constructors, get_clr_callback_fn_name)\n",
    "    callbacks_list.append(get_clr_callback_fn(cfg))\n",
    "\n",
    "## Main training block ##\n",
    "n_epochs = cfg[\"num_epochs\"]\n",
    "print(\n",
    "    f\"Starting Training with {n_epochs} epochs , {batch_size} batch size , {steps_per_epoch} steps per epoch , {validation_steps} validation steps......\"\n",
    ")\n",
    "if validation_steps <= 0:\n",
    "    raise RaiseError(\n",
    "        \"Not enough data for training, Increase image or Try reducing batchsize/epochs\"\n",
    "    )\n",
    "# FIXME : Make checkpoint\n",
    "start = perf_counter()\n",
    "history = the_model.fit(\n",
    "    train_batches,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_batches,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list,\n",
    ")\n",
    "end = perf_counter()\n",
    "print(f\"Training Finished , Time taken to train : {end-start} seconds\")\n",
    "print('\\n-----\\nHistory:')\n",
    "print(history.history.keys())\n",
    "print('\\n-----')\n",
    "\n",
    "# plot the training and validation accuracy and loss at each epoch\n",
    "print(\"Generating graphs ....\")\n",
    "if not os.path.exists(cfg[\"graph_location\"]):\n",
    "    os.mkdir(cfg[\"graph_location\"])\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    f\"{cfg['graph_location']}/training_validation_sparse_categorical_accuracy.png\"\n",
    ")\n",
    "print(f\"Graph generated at : {cfg['graph_location']}\")\n",
    "print(f\"accuracy {acc}\")\n",
    "print(f\"accuracy {val_acc}\")\n",
    "print(f\"loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/chips/OAM-319293-270962-19.tif'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/fair_split_train.csv\")\n",
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables are /home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar\n",
      " and /home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain\n",
      "Starting to prepare data for training\n",
      "ramp home is /home/annazan/fAIr-utilities\n",
      "python home is None\n",
      "variables are: src /home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar\n",
      " and dst:/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/annazan/fAIr-utilities/ramp-code/scripts/make_train_val_split_lists.py\", line 128, in <module>\n",
      "    main()\n",
      "  File \"/home/annazan/fAIr-utilities/ramp-code/scripts/make_train_val_split_lists.py\", line 91, in main\n",
      "    raise ValueError(f\"source directory {src_dir} is not readable\")\n",
      "ValueError: source directory /home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain/chips is not readable\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', '/home/annazan/fAIr-utilities/ramp-code/scripts/make_train_val_split_lists.py', '-src', '/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain/chips', '-pfx', '/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain/fair_split', '-trn', '0.85', '-val', '0.15']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m final_accuracy, final_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mramp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_home\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRAMP_HOME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/train.py:54\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_path, output_path, epoch_size, batch_size, model, model_home, freeze_layers)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables are \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m input_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m output_path)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to prepare data for training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43msplit_training_2_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone split\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m cfg \u001b[38;5;241m=\u001b[39m manage_fine_tuning_config(\n\u001b[1;32m     57\u001b[0m     output_path, epoch_size, batch_size, freeze_layers\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/prepare_data.py:66\u001b[0m, in \u001b[0;36msplit_training_2_validation\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m     50\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[1;32m     51\u001b[0m         [\n\u001b[1;32m     52\u001b[0m             python_exec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m         env\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron,\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# move all the VALIDATION chips, labels and masks to their new locations\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/prepare_data.py:50\u001b[0m, in \u001b[0;36msplit_training_2_validation\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Define the script as a string\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# SPLIT INTO TRAINING AND VALIDATION\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# script = f\"\"\"%run ramp-code/scripts/make_train_val_split_lists.py -src {dst_path}/chips -pfx {uid}_fair_split -trn 0.85 -val 0.15\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpython_exec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mRAMP_HOME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ramp-code/scripts/make_train_val_split_lists.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-src\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdst_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/chips\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-pfx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdst_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/fair_split\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-trn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.85\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.15\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/fair38/lib/python3.8/subprocess.py:415\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    413\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/miniconda3/envs/fair38/lib/python3.8/subprocess.py:516\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 516\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    517\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python', '/home/annazan/fAIr-utilities/ramp-code/scripts/make_train_val_split_lists.py', '-src', '/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain/chips', '-pfx', '/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibartrain/fair_split', '-trn', '0.85', '-val', '0.15']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "from hot_fair_utilities import train\n",
    "train_output = f\"{base_path}train\"\n",
    "final_accuracy, final_model_path = train(\n",
    "    input_path=preprocess_output,\n",
    "    output_path=train_output,\n",
    "    epoch_size=2,\n",
    "    batch_size=2,\n",
    "    model=\"ramp\",\n",
    "    model_home=os.environ[\"RAMP_HOME\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[here a tf file is created (weights + structure)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_accuracy,final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = f\"{os.getcwd()}/outputs/model51_td364/prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1PLe9S9BL8L",
    "outputId": "e4f3ce64-bbd6-4969-e49d-0f47dc9d6c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from hot_fair_utilities import predict\n",
    "\n",
    "\n",
    "print(f\"\\n**\\n** prediction output {prediction_output}\")\n",
    "print(f\"\\n**\\n** prediction input {base_path}prediction/input\")\n",
    "predict(\n",
    "    checkpoint_path=final_model_path,\n",
    "    input_path=f\"{base_path}prediction/input\",\n",
    "    prediction_path=prediction_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho4zn_5UBgS3",
    "outputId": "afdec49e-4172-45a6-e7b6-cd34522ca7a0"
   },
   "outputs": [],
   "source": [
    "from hot_fair_utilities import polygonize\n",
    "geojson_output= f\"{prediction_output}/prediction.geojson\"\n",
    "polygonize(\n",
    "    input_path=prediction_output, \n",
    "    output_path=geojson_output,\n",
    "    remove_inputs = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fairgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
