{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':/home/annazan/miniconda3/envs/fair38/lib/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"LD_LIBRARY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ":/home/annazan/miniconda3/envs/fair38/lib/\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/annazan/miniconda3/envs/fair38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ":/home/annazan/miniconda3/envs/fair38/lib/\n"
     ]
    }
   ],
   "source": [
    "!echo $LD_LIBRARY_PATH\n",
    "!source ~/.bashrc\n",
    "!echo $LD_LIBRARY_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI8nslrSgROI",
    "outputId": "2cbad97c-765f-4d2b-87df-773447500332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/annazan/fAIr-utilities\n",
      "/home/annazan/fAIr-utilities\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(os.getcwd())\n",
    "os.environ.update(os.environ)\n",
    "        # Add a new environment variable to the operating system\n",
    "os.environ[\"RAMP_HOME\"] = os.getcwd()\n",
    "# Print the environment variables to verify that the new variable was added\n",
    "print(os.environ[\"RAMP_HOME\"])\n",
    "sys.path.append('../')\n",
    "sys.path.append('../ramp-code/')\n",
    "sys.path.append('ramp-code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import cv2\n",
    "import ramp.utils\n",
    "import hot_fair_utilities\n",
    "\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/sample_2\"\n",
    "# base_path = \"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar\"\n",
    "# base_path = f\"{os.getcwd()}/ramp-data/test_data/1_Zanzibar\"\n",
    "base_path = f'{os.getcwd()}/ramp-data/test_data/model95_td370/'\n",
    "model_input_image_path = f\"{base_path}/input\"\n",
    "preprocess_output=f\"{base_path}/preprocessed\"\n",
    "train_output = f\"{base_path}/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hot_fair_utilities import preprocess\n",
    "\n",
    "# preprocess(\n",
    "#     input_path = model_input_image_path,\n",
    "#     output_path = preprocess_output,\n",
    "#     rasterize=True,\n",
    "#     # rasterize_options=[\"binary\"],\n",
    "#     rasterize_options=[\"binary\"],\n",
    "#     georeference_images=True,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make multimask path\n",
    "# !mkdir ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/\n",
    "# # Run script for multi-mask: https://github.com/kshitijrajsharma/ramp-code-fAIr/blob/ae33b11364f0a61f278ce9ff93446586704ea275/scripts/multi_masks_from_polygons.py\n",
    "# !python ramp-code/scripts/multi_masks_from_polygons.py -in_vecs ramp-data/test_data/1_Zanzibar/preprocessed/labels/ -in_chips ramp-data/test_data/1_Zanzibar/preprocessed/chips/ -out ramp-data/test_data/1_Zanzibar/preprocessed/multimasks/ -bwidth 2 -csp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp home is /home/annazan/fAIr-utilities\n",
      "python home is None\n",
      "variables are: src /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/\n",
      " and dst:/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/fair_split_train.csv\n",
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/fair_split_val.csv\n"
     ]
    }
   ],
   "source": [
    "preprocess_output=f\"{base_path}\"\n",
    "\n",
    "from hot_fair_utilities.training.prepare_data import split_training_2_validation\n",
    "x = split_training_2_validation(preprocess_output, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from ramp.training import (\n",
    "    callback_constructors,\n",
    "    loss_constructors,\n",
    "    metric_constructors,\n",
    "    model_constructors,\n",
    "    optimizer_constructors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hot_fair_utilities.training.run_training import manage_fine_tuning_config\n",
    "\n",
    "output_path=train_output\n",
    "epoch_size=2\n",
    "batch_size=2\n",
    "freeze_layers=False\n",
    "cfg = manage_fine_tuning_config(\n",
    "            output_path, epoch_size, batch_size, freeze_layers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'experiment_name': 'HOT-OSM Efficient-Unet Finetune model_set1_batch20_epoch20_imgAug', 'discard_experiment': False, 'logging': {'log_experiment': True, 'experiment_log_path': 'ramp-data/TRAIN/fAIr-experiments.csv', 'experiment_notes': 'Binary Mask model, batchsize 20, 20 epochs on HOT-OSM dataset 1 Multizoom, finetuning from RAMP saved model', 'fields_to_log': ['experiment_name', 'experiment_notes', 'timestamp', 'num_epochs', 'batch_size', 'output_img_shape', 'input_img_shape', 'get_loss_fn_name', 'use_saved_model', 'use_aug', 'use_early_stopping', 'use_clr', 'random_seed', 'num_classes', 'get_optimizer_fn_name', 'tb_logs_dir', 'get_model_fn_name', 'backbone', 'train_img_dir', 'train_mask_dir', 'val_img_dir', 'val_mask_dir']}, 'datasets': {'train_img_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/chips', 'train_mask_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/binarymasks', 'val_img_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/val-chips', 'val_mask_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/val-binarymasks'}, 'num_classes': 2, 'num_epochs': 2, 'batch_size': 2, 'input_img_shape': [256, 256], 'output_img_shape': [256, 256], 'loss': {'get_loss_fn_name': 'get_sparse_categorical_crossentropy_fn', 'loss_fn_parms': {}}, 'metrics': {'use_metrics': True, 'get_metrics_fn_names': ['get_precision_fn'], 'metrics_fn_parms': [{}]}, 'optimizer': {'get_optimizer_fn_name': 'get_adam_optimizer', 'optimizer_fn_parms': {'learning_rate': 0.0003}}, 'model': {'get_model_fn_name': 'get_effunet_model', 'model_fn_parms': {'backbone': 'efficientnetb0', 'classes': ['background', 'buildings']}}, 'saved_model': {'use_saved_model': True, 'saved_model_path': 'ramp-code/ramp/checkpoint.tf', 'save_optimizer_state': False}, 'augmentation': {'use_aug': True, 'get_augmentation_fn_name': 'get_augmentation_fn', 'aug_list': ['Rotate', 'ColorJitter'], 'aug_parms': [{'border_mode': 'BORDER_CONSTANT', 'interpolation': 'INTER_NEAREST', 'value': [0.0, 0.0, 0.0], 'mask_value': 0, 'p': 0.7}, {'p': 0.7}]}, 'early_stopping': {'use_early_stopping': True, 'early_stopping_parms': {'monitor': 'val_loss', 'min_delta': 0.005, 'patience': 50, 'verbose': 0, 'mode': 'auto', 'restore_best_weights': False}}, 'cyclic_learning_scheduler': {'use_clr': False, 'get_clr_callback_fn_name': 'get_clr_callback_fn', 'clr_callback_parms': {'mode': 'triangular2', 'stepsize': 8, 'max_lr': 0.0001, 'base_lr': 3.25e-06}, 'clr_plot_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/plots'}, 'tensorboard': {'use_tb': True, 'tb_logs_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/logs', 'get_tb_callback_fn_name': 'get_tb_callback_fn', 'tb_callback_parms': {'histogram_freq': 1, 'update_freq': 'batch'}}, 'prediction_logging': {'use_prediction_logging': True, 'get_prediction_logging_fn_name': 'get_pred_logging_callback_fn'}, 'model_checkpts': {'use_model_checkpts': True, 'model_checkpts_dir': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/model-checkpts', 'get_model_checkpt_callback_fn_name': 'get_model_checkpt_callback_fn', 'model_checkpt_callback_parms': {'mode': 'max', 'save_best_only': True}}, 'feedback': {'freeze_layers': False}, 'random_seed': 20220523, 'freeze_layers': False, 'graph_location': '/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/graphs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Config:\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_experiment = False\n",
    "if \"discard_experiment\" in cfg:\n",
    "    discard_experiment = cfg[\"discard_experiment\"]\n",
    "cfg[\"timestamp\"] = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric constructor function: get_precision_fn\n",
      "Metric constructor function: get_iou_fn\n"
     ]
    }
   ],
   "source": [
    "# specify a function that will construct the loss function\n",
    "get_loss_fn_name = cfg[\"loss\"][\"get_loss_fn_name\"]\n",
    "\n",
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "get_loss_fn_name = \"get_categorical_crossentropy_fn\"\n",
    "#---\n",
    "\n",
    "get_loss_fn = getattr(loss_constructors, get_loss_fn_name)\n",
    "# Construct the loss function\n",
    "loss_fn = get_loss_fn(cfg)\n",
    "\n",
    "the_metrics = []\n",
    "if cfg[\"metrics\"][\"use_metrics\"]:\n",
    "    get_metrics_fn_names = cfg[\"metrics\"][\"get_metrics_fn_names\"]\n",
    "    get_metrics_fn_parms = cfg[\"metrics\"][\"metrics_fn_parms\"]\n",
    "    assert len(get_metrics_fn_names) == len(get_metrics_fn_parms)\n",
    "    \n",
    "    \n",
    "    #---\n",
    "    # TODO: manually changing here for OHE experiment\n",
    "    get_metrics_fn_names = [\"get_precision_fn\", \"get_iou_fn\"]\n",
    "    get_metrics_fn_parms = [{}, {}]\n",
    "    #---\n",
    "    for get_mf_name, mf_parms in zip(get_metrics_fn_names, get_metrics_fn_parms):\n",
    "        \n",
    "        get_metric_fn = getattr(metric_constructors, get_mf_name)\n",
    "        print(f\"Metric constructor function: {get_metric_fn.__name__}\")\n",
    "        metric_fn = get_metric_fn(mf_parms)\n",
    "        the_metrics.append(metric_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: importing saved model /home/annazan/fAIr-utilities/ramp-code/ramp/checkpoint.tf\n",
      "-------\n",
      "-------[<keras.metrics.metrics.Precision object at 0x7f468851ed60>, <keras.metrics.metrics.IoU object at 0x7f46885313d0>]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#### construct optimizer ####\n",
    "get_optimizer_fn_name = cfg[\"optimizer\"][\"get_optimizer_fn_name\"]\n",
    "get_optimizer_fn = getattr(optimizer_constructors, get_optimizer_fn_name)\n",
    "\n",
    "optimizer = get_optimizer_fn(cfg)\n",
    "\n",
    "the_model = None\n",
    "\n",
    "# SG: Using the saved model in this cell\n",
    "working_ramp_home = os.environ[\"RAMP_HOME\"]\n",
    "# load (construct) the model\n",
    "model_path = Path(working_ramp_home) / cfg[\"saved_model\"][\"saved_model_path\"]\n",
    "print(f\"Model: importing saved model {str(model_path)}\")\n",
    "the_model = tf.keras.models.load_model(model_path)\n",
    "assert (\n",
    "    the_model is not None\n",
    "), f\"the saved model was not constructed: {model_path}\"\n",
    "\n",
    "if cfg[\"freeze_layers\"]:\n",
    "    for layer in the_model.layers:\n",
    "        layer.trainable = False  # freeze previous layers only update new layers\n",
    "        # print(\"Setting previous model layers traininable : False\")\n",
    "\n",
    "\n",
    "print(\"-------\")\n",
    "print(f'-------{the_metrics}')\n",
    "print(\"-------\")\n",
    "\n",
    "# If you don't want to save the original state of training, recompile the model.\n",
    "the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[the_metrics])\n",
    "# the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[precision_class_0,precision_class_1])\n",
    "\n",
    "# the_model.compile(optimizer = optimizer,\n",
    "#    loss=loss_fn,\n",
    "#    metrics = [get_iou_coef_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.609438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of non-sparse loss fn with probs over labels and OHE labels (total 4 classes)\n",
    "y_true = tf.one_hot([0, 1], depth=4, axis=-1)\n",
    "y_pred = [[0.05, 0.95, 0, 0], [0.1, 0.8, 0.1, 0]]\n",
    "loss_fn(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.609438>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model summary:\")\n",
    "# print(the_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "def ohe_batches(batches: tf.data.Dataset, depth=4) -> tf.data.Dataset:\n",
    "    \"\"\"For given batches and depth map sparse labels to OHE.\"\"\"\n",
    "    return batches.map(lambda x, y: (x, tf.one_hot(y[..., -1], depth, axis=-1)))\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "* train img dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/chips\n",
      "* train mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/binarymasks\n",
      "* input img shape[256, 256]\n",
      "* output img shape[256, 256]\n",
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "from ramp.training.augmentation_constructors import get_augmentation_fn\n",
    "from ramp.utils.misc_ramp_utils import get_num_files\n",
    "from ramp.data_mgmt.data_generator import (\n",
    "    test_batches_from_gtiff_dirs,\n",
    "    training_batches_from_gtiff_dirs,\n",
    ")\n",
    "#### define data directories ####\n",
    "train_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_img_dir\"]\n",
    "train_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_mask_dir\"]\n",
    "val_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_img_dir\"]\n",
    "val_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_mask_dir\"]\n",
    "\n",
    "#### get the augmentation transform ####\n",
    "# aug = None\n",
    "if cfg[\"augmentation\"][\"use_aug\"]:\n",
    "    aug = get_augmentation_fn(cfg)\n",
    "\n",
    "## RUNTIME Parameters\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "input_img_shape = cfg[\"input_img_shape\"]\n",
    "output_img_shape = cfg[\"output_img_shape\"]\n",
    "\n",
    "n_training = get_num_files(train_img_dir, \"*.tif\")\n",
    "n_val = get_num_files(val_img_dir, \"*.tif\")\n",
    "steps_per_epoch = n_training // batch_size\n",
    "validation_steps = n_val // batch_size\n",
    "# Testing step , not recommended\n",
    "if validation_steps <= 0:\n",
    "    validation_steps = 1\n",
    "\n",
    "# add these back to the config\n",
    "# in case they are needed by callbacks\n",
    "cfg[\"runtime\"] = {}\n",
    "cfg[\"runtime\"][\"n_training\"] = n_training\n",
    "cfg[\"runtime\"][\"n_val\"] = n_val\n",
    "cfg[\"runtime\"][\"steps_per_epoch\"] = steps_per_epoch\n",
    "cfg[\"runtime\"][\"validation_steps\"] = validation_steps\n",
    "\n",
    "train_batches = None\n",
    "\n",
    "if aug is not None:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir,\n",
    "        train_mask_dir,\n",
    "        batch_size,\n",
    "        input_img_shape,\n",
    "        output_img_shape,\n",
    "        transforms=aug,\n",
    "    )\n",
    "else:\n",
    "    train_batches = training_batches_from_gtiff_dirs(\n",
    "        train_img_dir, train_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "    )\n",
    "assert train_batches is not None, \"training batches were not constructed\"\n",
    "print(f\"-------\\n* train img dir{train_img_dir}\\n* train mask dir{train_mask_dir}\")\n",
    "print(f\"* input img shape{input_img_shape}\\n* output img shape{output_img_shape}\")\n",
    "\n",
    "\n",
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "train_batches = ohe_batches(train_batches)\n",
    "#---\n",
    "print(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Batches are a tf.data.Dataset type\n",
    "print(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a single batch as numpy to explore\n",
    "iter = tf.data.Dataset.as_numpy_iterator(train_batches)\n",
    "(X_batch, y_true_batch) = iter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_batch[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is: 2\n",
      "Example X entry: [0.06786785 0.06786785 0.06786785]\n",
      "Input data shape (X): (2, 256, 256, 3)\n",
      "Ground truth data shape (y_true): (2, 256, 256, 4)\n",
      "Example y_true:  [0. 1. 0. 0.]\n",
      "The unique labels in the y_true: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Print useful info\n",
    "print(\"Batch size is:\", X_batch.shape[0])\n",
    "# Appears to be floats between 0 and 1\n",
    "print(\"Example X entry:\", X_batch[0, 0, 0, :])\n",
    "print(\"Input data shape (X):\", X_batch.shape)\n",
    "print(\"Ground truth data shape (y_true):\", y_true_batch.shape)\n",
    "print(\"Example y_true: \", y_true_batch[1, 0, 0, :])\n",
    "print(f\"The unique labels in the y_true: {np.unique(y_true_batch[0, :, :, 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Get some predictions from the model for the batch\n",
    "y_pred_batch = the_model.predict(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions y_pred_batch are: (2, 256, 256, 4)\n"
     ]
    }
   ],
   "source": [
    "# Shape of output predictions\n",
    "print(\"Predictions y_pred_batch are:\", y_pred_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9108499e-01 4.7262857e-04 8.2368916e-03 2.0547237e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example single pixel prediction\n",
    "single_prediction = y_pred_batch[0, 0, 0, :]\n",
    "print(single_prediction)\n",
    "\n",
    "# Single prediction sums to 1: probabilties over the four categories of the model\n",
    "single_prediction.sum().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6845751>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.loss(y_true_batch, y_pred_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "* val img dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/val-chips\n",
      "* val mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/val-binarymasks\n",
      "-------\n",
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float32, name=None))>\n",
      "*\n",
      "*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation batches\n",
    "val_batches = test_batches_from_gtiff_dirs(\n",
    "    val_img_dir, val_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    ")\n",
    "\n",
    "#---\n",
    "# TODO: manually changing here for OHE experiment\n",
    "val_batches = ohe_batches(val_batches)\n",
    "#---\n",
    "\n",
    "assert val_batches is not None, \"validation batches were not constructed\"\n",
    "print(f\"-------\\n* val img dir{val_img_dir}\\n* val mask dir{val_mask_dir}\\n-------\")\n",
    "print(val_batches)\n",
    "print('*\\n*\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "# ---------------\n",
    "## Callbacks ##\n",
    "callbacks_list = []\n",
    "\n",
    "if not discard_experiment:\n",
    "    # get model checkpoint callback\n",
    "    if cfg[\"model_checkpts\"][\"use_model_checkpts\"]:\n",
    "        get_model_checkpt_callback_fn_name = cfg[\"model_checkpts\"][\n",
    "            \"get_model_checkpt_callback_fn_name\"\n",
    "        ]\n",
    "        get_model_checkpt_callback_fn = getattr(\n",
    "            callback_constructors, get_model_checkpt_callback_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_model_checkpt_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard callback\n",
    "    if cfg[\"tensorboard\"][\"use_tb\"]:\n",
    "        get_tb_callback_fn_name = cfg[\"tensorboard\"][\"get_tb_callback_fn_name\"]\n",
    "        get_tb_callback_fn = getattr(callback_constructors, get_tb_callback_fn_name)\n",
    "        callbacks_list.append(get_tb_callback_fn(cfg))\n",
    "\n",
    "    # get tensorboard model prediction logging callback\n",
    "    if cfg[\"prediction_logging\"][\"use_prediction_logging\"]:\n",
    "        assert cfg[\"tensorboard\"][\n",
    "            \"use_tb\"\n",
    "        ], \"Tensorboard logging must be turned on to enable prediction logging\"\n",
    "        get_prediction_logging_fn_name = cfg[\"prediction_logging\"][\n",
    "            \"get_prediction_logging_fn_name\"\n",
    "        ]\n",
    "        get_prediction_logging_fn = getattr(\n",
    "            callback_constructors, get_prediction_logging_fn_name\n",
    "        )\n",
    "        callbacks_list.append(get_prediction_logging_fn(the_model, cfg))\n",
    "\n",
    "# free up RAM\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "if cfg[\"early_stopping\"][\"use_early_stopping\"]:\n",
    "    callbacks_list.append(callback_constructors.get_early_stopping_callback_fn(cfg))\n",
    "\n",
    "    # get cyclic learning scheduler callback\n",
    "if cfg[\"cyclic_learning_scheduler\"][\"use_clr\"]:\n",
    "    assert not cfg[\"early_stopping\"][\n",
    "        \"use_early_stopping\"\n",
    "    ], \"cannot use early_stopping with cycling_learning_scheduler\"\n",
    "    get_clr_callback_fn_name = cfg[\"cyclic_learning_scheduler\"][\n",
    "        \"get_clr_callback_fn_name\"\n",
    "    ]\n",
    "    get_clr_callback_fn = getattr(callback_constructors, get_clr_callback_fn_name)\n",
    "    callbacks_list.append(get_clr_callback_fn(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/model-checkpts/20240306-140533/model_20240306-140533_{epoch:03d}_{val_precision_1:.3f}.tf'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call = callbacks_list[0]\n",
    "call.filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with 10 epochs , 2 batch size , 71 steps per epoch , 12 validation steps......\n",
      "Epoch 1/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8504 - precision_1: 0.6577 - iou: 0.4382INFO:tensorflow:Assets written to: /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/model-checkpts/20240306-140533/model_20240306-140533_001_0.929.tf/assets\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "71/71 [==============================] - 38s 421ms/step - loss: 0.8504 - precision_1: 0.6577 - iou: 0.4382 - val_loss: 0.3638 - val_precision_1: 0.9293 - val_iou: 0.4888\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.3959 - precision_1: 0.7676 - iou: 0.44\n",
      "71/71 [==============================] - 9s 100ms/step - loss: 0.3959 - precision_1: 0.7676 - iou: 0.4444 - val_loss: 0.3034 - val_precision_1: 0.9128 - val_iou: 0.4872\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3433 - precision_1: 0.7639 - iou: 0.4408INFO:tensorflow:Assets written to: /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/model-checkpts/20240306-140533/model_20240306-140533_003_0.934.tf/assets\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "71/71 [==============================] - 27s 389ms/step - loss: 0.3433 - precision_1: 0.7639 - iou: 0.4408 - val_loss: 0.2111 - val_precision_1: 0.9338 - val_iou: 0.3926\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 27ms/steploss: 0.3106 - precision_1: 0.7620 - iou: 0.43\n",
      "71/71 [==============================] - 7s 102ms/step - loss: 0.3106 - precision_1: 0.7620 - iou: 0.4360 - val_loss: 0.1667 - val_precision_1: 0.8477 - val_iou: 0.4378\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 35ms/steploss: 0.2639 - precision_1: 0.8072 - iou: 0.43\n",
      "71/71 [==============================] - 7s 102ms/step - loss: 0.2639 - precision_1: 0.8072 - iou: 0.4367 - val_loss: 0.1876 - val_precision_1: 0.8620 - val_iou: 0.4595\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 27ms/steploss: 0.2574 - precision_1: 0.7969 - iou: 0.44\n",
      "71/71 [==============================] - 7s 102ms/step - loss: 0.2574 - precision_1: 0.7969 - iou: 0.4413 - val_loss: 0.1707 - val_precision_1: 0.7954 - val_iou: 0.4494\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 27ms/steploss: 0.2696 - precision_1: 0.7852 - iou: 0.43\n",
      "71/71 [==============================] - 7s 102ms/step - loss: 0.2696 - precision_1: 0.7852 - iou: 0.4399 - val_loss: 0.1381 - val_precision_1: 0.8803 - val_iou: 0.3899\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 27ms/steploss: 0.2609 - precision_1: 0.7738 - iou: 0.43\n",
      "71/71 [==============================] - 7s 102ms/step - loss: 0.2609 - precision_1: 0.7738 - iou: 0.4391 - val_loss: 0.1475 - val_precision_1: 0.8602 - val_iou: 0.3908\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.1967 - precision_1: 0.8491 - iou: 0.43\n",
      "71/71 [==============================] - 7s 104ms/step - loss: 0.1967 - precision_1: 0.8491 - iou: 0.4385 - val_loss: 0.1441 - val_precision_1: 0.8509 - val_iou: 0.3820\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.2408 - precision_1: 0.7973 - iou: 0.43\n",
      "71/71 [==============================] - 7s 102ms/step - loss: 0.2408 - precision_1: 0.7973 - iou: 0.4390 - val_loss: 0.1342 - val_precision_1: 0.9142 - val_iou: 0.4048\n",
      "Training Finished , Time taken to train : 125.58609264000006 seconds\n",
      "\n",
      "-----\n",
      "History:\n",
      "dict_keys(['loss', 'precision_1', 'iou', 'val_loss', 'val_precision_1', 'val_iou'])\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "\n",
    "## Main training block ##\n",
    "n_epochs = cfg[\"num_epochs\"]\n",
    "# SG: manually make this 10\n",
    "n_epochs = 10\n",
    "print(\n",
    "    f\"Starting Training with {n_epochs} epochs , {batch_size} batch size , {steps_per_epoch} steps per epoch , {validation_steps} validation steps......\"\n",
    ")\n",
    "if validation_steps <= 0:\n",
    "    raise RaiseError(\n",
    "        \"Not enough data for training, Increase image or Try reducing batchsize/epochs\"\n",
    "    )\n",
    "# FIXME : Make checkpoint\n",
    "start = perf_counter()\n",
    "history = the_model.fit(\n",
    "    train_batches,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_batches,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list,\n",
    ")\n",
    "end = perf_counter()\n",
    "print(f\"Training Finished , Time taken to train : {end-start} seconds\")\n",
    "print('\\n-----\\nHistory:')\n",
    "print(history.history.keys())\n",
    "print('\\n-----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graphs ....\n",
      "Graph generated at : /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370//train/graphs\n",
      "accuracy [0.6577438116073608, 0.7676373720169067, 0.7638641595840454, 0.7620459198951721, 0.8071892857551575, 0.7969008684158325, 0.785211980342865, 0.7737615704536438, 0.8491490483283997, 0.7972997426986694]\n",
      "accuracy [0.9293320775032043, 0.9128451347351074, 0.9338300228118896, 0.8476808667182922, 0.8619670271873474, 0.7954358458518982, 0.8803215026855469, 0.8602098226547241, 0.8509362936019897, 0.9141762852668762]\n",
      "loss [0.8504456281661987, 0.3959389925003052, 0.3432747721672058, 0.31064924597740173, 0.2639405131340027, 0.2573508024215698, 0.2696053683757782, 0.260934442281723, 0.19671539962291718, 0.24077078700065613]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot the training and validation accuracy and loss at each epoch\n",
    "print(\"Generating graphs ....\")\n",
    "if not os.path.exists(cfg[\"graph_location\"]):\n",
    "    os.mkdir(cfg[\"graph_location\"])\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "# val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "#---\n",
    "# TODO: updated for OHE\n",
    "acc = history.history[\"precision_1\"]\n",
    "val_acc = history.history[\"val_precision_1\"]\n",
    "#---\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    f\"{cfg['graph_location']}/training_validation_sparse_categorical_accuracy.png\"\n",
    ")\n",
    "print(f\"Graph generated at : {cfg['graph_location']}\")\n",
    "print(f\"accuracy {acc}\")\n",
    "print(f\"accuracy {val_acc}\")\n",
    "print(f\"loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'precision_1', 'iou', 'val_loss', 'val_precision_1', 'val_iou'])\n",
      "[0.4887550175189972, 0.487190842628479, 0.3925529420375824, 0.43777579069137573, 0.4594821333885193, 0.449368953704834, 0.3898741602897644, 0.3908065855503082, 0.38196274638175964, 0.40484076738357544]\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "print(history.history[\"val_iou\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # APPENDIX: from copying across\n",
    "\n",
    "# #### construct optimizer ####\n",
    "# get_optimizer_fn_name = cfg[\"optimizer\"][\"get_optimizer_fn_name\"]\n",
    "# get_optimizer_fn = getattr(optimizer_constructors, get_optimizer_fn_name)\n",
    "\n",
    "# optimizer = get_optimizer_fn(cfg)\n",
    "\n",
    "# the_model = None\n",
    "\n",
    "# if cfg[\"saved_model\"][\"use_saved_model\"]:\n",
    "#     # load (construct) the model\n",
    "#     model_path = Path(working_ramp_home) / cfg[\"saved_model\"][\"saved_model_path\"]\n",
    "#     print(f\"Model: importing saved model {str(model_path)}\")\n",
    "#     the_model = tf.keras.models.load_model(model_path)\n",
    "#     assert (\n",
    "#         the_model is not None\n",
    "#     ), f\"the saved model was not constructed: {model_path}\"\n",
    "\n",
    "#     if cfg[\"freeze_layers\"]:\n",
    "#         for layer in the_model.layers:\n",
    "#             layer.trainable = False  # freeze previous layers only update new layers\n",
    "#             # print(\"Setting previous model layers traininable : False\")\n",
    "\n",
    "#     if not cfg[\"saved_model\"][\"save_optimizer_state\"]:\n",
    "#         print(\"-------\")\n",
    "#         print(f'-------{the_metrics}')\n",
    "#         print(\"-------\")\n",
    "        \n",
    "#         # For class 0\n",
    "#         precision_class_0 = Precision(class_id=0)\n",
    "#         # For class 1\n",
    "#         precision_class_1 = Precision(class_id=1)\n",
    "#         metrics=[precision_class_0,precision_class_1]\n",
    "#         print(f'-------{the_metrics}')\n",
    "#         print(\"-------\")\n",
    "        \n",
    "#         # If you don't want to save the original state of training, recompile the model.\n",
    "#         the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[the_metrics])\n",
    "#         # the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[precision_class_0,precision_class_1])\n",
    "        \n",
    "#         # the_model.compile(optimizer = optimizer,\n",
    "#         #    loss=loss_fn,\n",
    "#         #    metrics = [get_iou_coef_fn])\n",
    "\n",
    "# if not cfg[\"saved_model\"][\"use_saved_model\"]:\n",
    "#     get_model_fn_name = cfg[\"model\"][\"get_model_fn_name\"]\n",
    "#     get_model_fn = getattr(model_constructors, get_model_fn_name)\n",
    "#     the_model = get_model_fn(cfg)\n",
    "\n",
    "#     assert the_model is not None, f\"the model was not constructed: {model_path}\"\n",
    "#     the_model.compile(optimizer=optimizer, loss=loss_fn, metrics=the_metrics)\n",
    "\n",
    "# print(the_model)\n",
    "# cfg[\"datasets\"]\n",
    "\n",
    "# #### define data directories ####\n",
    "# train_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_img_dir\"]\n",
    "# train_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"train_mask_dir\"]\n",
    "# val_img_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_img_dir\"]\n",
    "# val_mask_dir = Path(working_ramp_home) / cfg[\"datasets\"][\"val_mask_dir\"]\n",
    "\n",
    "# #### get the augmentation transform ####\n",
    "# # aug = None\n",
    "# if cfg[\"augmentation\"][\"use_aug\"]:\n",
    "#     aug = get_augmentation_fn(cfg)\n",
    "\n",
    "# ## RUNTIME Parameters\n",
    "# batch_size = cfg[\"batch_size\"]\n",
    "# input_img_shape = cfg[\"input_img_shape\"]\n",
    "# output_img_shape = cfg[\"output_img_shape\"]\n",
    "\n",
    "# n_training = get_num_files(train_img_dir, \"*.tif\")\n",
    "# n_val = get_num_files(val_img_dir, \"*.tif\")\n",
    "# steps_per_epoch = n_training // batch_size\n",
    "# validation_steps = n_val // batch_size\n",
    "# # Testing step , not recommended\n",
    "# if validation_steps <= 0:\n",
    "#     validation_steps = 1\n",
    "\n",
    "# # add these back to the config\n",
    "# # in case they are needed by callbacks\n",
    "# cfg[\"runtime\"] = {}\n",
    "# cfg[\"runtime\"][\"n_training\"] = n_training\n",
    "# cfg[\"runtime\"][\"n_val\"] = n_val\n",
    "# cfg[\"runtime\"][\"steps_per_epoch\"] = steps_per_epoch\n",
    "# cfg[\"runtime\"][\"validation_steps\"] = validation_steps\n",
    "\n",
    "# train_batches = None\n",
    "\n",
    "# if aug is not None:\n",
    "#     train_batches = training_batches_from_gtiff_dirs(\n",
    "#         train_img_dir,\n",
    "#         train_mask_dir,\n",
    "#         batch_size,\n",
    "#         input_img_shape,\n",
    "#         output_img_shape,\n",
    "#         transforms=aug,\n",
    "#     )\n",
    "# else:\n",
    "#     train_batches = training_batches_from_gtiff_dirs(\n",
    "#         train_img_dir, train_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "#     )\n",
    "\n",
    "# assert train_batches is not None, \"training batches were not constructed\"\n",
    "# print(f\"-------\\n* train img dir{train_img_dir}\\n* train mask dir{train_mask_dir}\")\n",
    "# print(f\"* input img shape{input_img_shape}\\n* output img shape{output_img_shape}\")\n",
    "\n",
    "# print(train_batches)\n",
    "\n",
    "# val_batches = test_batches_from_gtiff_dirs(\n",
    "#     val_img_dir, val_mask_dir, batch_size, input_img_shape, output_img_shape\n",
    "# )\n",
    "\n",
    "# assert val_batches is not None, \"validation batches were not constructed\"\n",
    "# print(f\"-------\\n* val img dir{val_img_dir}\\n* val mask dir{val_mask_dir}\\n-------\")\n",
    "# print(val_batches)\n",
    "# print('*\\n*\\n')\n",
    "\n",
    "# ## Callbacks ##\n",
    "# callbacks_list = []\n",
    "\n",
    "# if not discard_experiment:\n",
    "#     # get model checkpoint callback\n",
    "#     if cfg[\"model_checkpts\"][\"use_model_checkpts\"]:\n",
    "#         get_model_checkpt_callback_fn_name = cfg[\"model_checkpts\"][\n",
    "#             \"get_model_checkpt_callback_fn_name\"\n",
    "#         ]\n",
    "#         get_model_checkpt_callback_fn = getattr(\n",
    "#             callback_constructors, get_model_checkpt_callback_fn_name\n",
    "#         )\n",
    "#         callbacks_list.append(get_model_checkpt_callback_fn(cfg))\n",
    "\n",
    "#     # get tensorboard callback\n",
    "#     if cfg[\"tensorboard\"][\"use_tb\"]:\n",
    "#         get_tb_callback_fn_name = cfg[\"tensorboard\"][\"get_tb_callback_fn_name\"]\n",
    "#         get_tb_callback_fn = getattr(callback_constructors, get_tb_callback_fn_name)\n",
    "#         callbacks_list.append(get_tb_callback_fn(cfg))\n",
    "\n",
    "#     # get tensorboard model prediction logging callback\n",
    "#     if cfg[\"prediction_logging\"][\"use_prediction_logging\"]:\n",
    "#         assert cfg[\"tensorboard\"][\n",
    "#             \"use_tb\"\n",
    "#         ], \"Tensorboard logging must be turned on to enable prediction logging\"\n",
    "#         get_prediction_logging_fn_name = cfg[\"prediction_logging\"][\n",
    "#             \"get_prediction_logging_fn_name\"\n",
    "#         ]\n",
    "#         get_prediction_logging_fn = getattr(\n",
    "#             callback_constructors, get_prediction_logging_fn_name\n",
    "#         )\n",
    "#         callbacks_list.append(get_prediction_logging_fn(the_model, cfg))\n",
    "\n",
    "# # free up RAM\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# if cfg[\"early_stopping\"][\"use_early_stopping\"]:\n",
    "#     callbacks_list.append(callback_constructors.get_early_stopping_callback_fn(cfg))\n",
    "\n",
    "#     # get cyclic learning scheduler callback\n",
    "# if cfg[\"cyclic_learning_scheduler\"][\"use_clr\"]:\n",
    "#     assert not cfg[\"early_stopping\"][\n",
    "#         \"use_early_stopping\"\n",
    "#     ], \"cannot use early_stopping with cycling_learning_scheduler\"\n",
    "#     get_clr_callback_fn_name = cfg[\"cyclic_learning_scheduler\"][\n",
    "#         \"get_clr_callback_fn_name\"\n",
    "#     ]\n",
    "#     get_clr_callback_fn = getattr(callback_constructors, get_clr_callback_fn_name)\n",
    "#     callbacks_list.append(get_clr_callback_fn(cfg))\n",
    "\n",
    "# ## Main training block ##\n",
    "# n_epochs = cfg[\"num_epochs\"]\n",
    "# print(\n",
    "#     f\"Starting Training with {n_epochs} epochs , {batch_size} batch size , {steps_per_epoch} steps per epoch , {validation_steps} validation steps......\"\n",
    "# )\n",
    "# if validation_steps <= 0:\n",
    "#     raise RaiseError(\n",
    "#         \"Not enough data for training, Increase image or Try reducing batchsize/epochs\"\n",
    "#     )\n",
    "# # FIXME : Make checkpoint\n",
    "# start = perf_counter()\n",
    "# history = the_model.fit(\n",
    "#     train_batches,\n",
    "#     epochs=n_epochs,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_data=val_batches,\n",
    "#     validation_steps=validation_steps,\n",
    "#     callbacks=callbacks_list,\n",
    "# )\n",
    "# end = perf_counter()\n",
    "# print(f\"Training Finished , Time taken to train : {end-start} seconds\")\n",
    "# print('\\n-----\\nHistory:')\n",
    "# print(history.history.keys())\n",
    "# print('\\n-----')\n",
    "\n",
    "# # plot the training and validation accuracy and loss at each epoch\n",
    "# print(\"Generating graphs ....\")\n",
    "# if not os.path.exists(cfg[\"graph_location\"]):\n",
    "#     os.mkdir(cfg[\"graph_location\"])\n",
    "\n",
    "# loss = history.history[\"loss\"]\n",
    "# # val_loss = history.history[\"val_loss\"]\n",
    "# epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "# val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "# # Plot training and validation accuracy\n",
    "# plt.plot(epochs, acc, \"y\", label=\"Training Accuracy\")\n",
    "# plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
    "\n",
    "# # Set labels and title\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig(\n",
    "#     f\"{cfg['graph_location']}/training_validation_sparse_categorical_accuracy.png\"\n",
    "# )\n",
    "# print(f\"Graph generated at : {cfg['graph_location']}\")\n",
    "# print(f\"accuracy {acc}\")\n",
    "# print(f\"accuracy {val_acc}\")\n",
    "# print(f\"loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/chips/OAM-319292-270962-19.tif'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/annazan/fAIr-utilities/ramp-data/test_data/1_Zanzibar/train/fair_split_train.csv\")\n",
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables are /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/\n",
      " and /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train\n",
      "Starting to prepare data for training\n",
      "ramp home is /home/annazan/fAIr-utilities\n",
      "python home is None\n",
      "variables are: src /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/\n",
      " and dst:/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/fair_split_train.csv\n",
      "Writing /home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/fair_split_val.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done split\n",
      "Data is ready for training\n",
      "Metric constructor function: get_precision_fn\n",
      "Model: importing saved model /home/annazan/fAIr-utilities/ramp-code/ramp/checkpoint.tf\n",
      "-------\n",
      "-------[<keras.metrics.metrics.Precision object at 0x7f46893cf0d0>]\n",
      "-------\n",
      "-------[<keras.metrics.metrics.Precision object at 0x7f46893cf0d0>]\n",
      "-------\n",
      "<keras.engine.functional.Functional object at 0x7f470fc4ce80>\n",
      "-------\n",
      "* train img dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/chips\n",
      "* train mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/binarymasks\n",
      "* input img shape[256, 256]\n",
      "* output img shape[256, 256]\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.uint8, name=None))>\n",
      "-------\n",
      "* val img dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/val-chips\n",
      "* val mask dir/home/annazan/fAIr-utilities/ramp-data/test_data/model95_td370/train/val-binarymasks\n",
      "-------\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.uint8, name=None))>\n",
      "*\n",
      "*\n",
      "\n",
      "Starting Training with 2 epochs , 2 batch size , 71 steps per epoch , 12 validation steps......\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 894, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 987, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 501, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/metrics/metrics.py\", line 818, in update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 619, in update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 256, 256, 4) and (None, 256, 256, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhot_fair_utilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m      2\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m final_accuracy, final_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mramp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_home\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRAMP_HOME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/train.py:60\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_path, output_path, epoch_size, batch_size, model, model_home, freeze_layers)\u001b[0m\n\u001b[1;32m     56\u001b[0m cfg \u001b[38;5;241m=\u001b[39m manage_fine_tuning_config(\n\u001b[1;32m     57\u001b[0m     output_path, epoch_size, batch_size, freeze_layers\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is ready for training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mrun_main_train_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracting highest accuracy model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m final_accuracy, final_model_path \u001b[38;5;241m=\u001b[39m extract_highest_accuracy_model(output_path)\n",
      "File \u001b[0;32m~/fAIr-utilities/hot_fair_utilities/training/run_training.py:323\u001b[0m, in \u001b[0;36mrun_main_train_code\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# FIXME : Make checkpoint\u001b[39;00m\n\u001b[1;32m    322\u001b[0m start \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m--> 323\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mthe_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m end \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Finished , Time taken to train : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1icmzkd6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 894, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/training.py\", line 987, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 501, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/metrics/metrics.py\", line 818, in update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    File \"/home/annazan/miniconda3/envs/fair38/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 619, in update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 256, 256, 4) and (None, 256, 256, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from hot_fair_utilities import train\n",
    "train_output = f\"{base_path}train\"\n",
    "final_accuracy, final_model_path = train(\n",
    "    input_path=preprocess_output,\n",
    "    output_path=train_output,\n",
    "    epoch_size=2,\n",
    "    batch_size=2,\n",
    "    model=\"ramp\",\n",
    "    model_home=os.environ[\"RAMP_HOME\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[here a tf file is created (weights + structure)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_accuracy,final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = f\"{os.getcwd()}/outputs/model51_td364/prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1PLe9S9BL8L",
    "outputId": "e4f3ce64-bbd6-4969-e49d-0f47dc9d6c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from hot_fair_utilities import predict\n",
    "\n",
    "\n",
    "print(f\"\\n**\\n** prediction output {prediction_output}\")\n",
    "print(f\"\\n**\\n** prediction input {base_path}prediction/input\")\n",
    "predict(\n",
    "    checkpoint_path=final_model_path,\n",
    "    input_path=f\"{base_path}prediction/input\",\n",
    "    prediction_path=prediction_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho4zn_5UBgS3",
    "outputId": "afdec49e-4172-45a6-e7b6-cd34522ca7a0"
   },
   "outputs": [],
   "source": [
    "from hot_fair_utilities import polygonize\n",
    "geojson_output= f\"{prediction_output}/prediction.geojson\"\n",
    "polygonize(\n",
    "    input_path=prediction_output, \n",
    "    output_path=geojson_output,\n",
    "    remove_inputs = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fairgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
